[{"title":"Spring Security 如何优雅的过滤掉静态页面请求","url":"http://heqiao2010.github.io/2020/06/30/Spring_Security如何优雅的过滤掉静态页面请求/","content":"\n在最近的开发过程中遇到一个问题，某个java服务采用spring security开启了认证，但是同时又需要采用swagger生成在线api文档，如果从这些请求中过滤掉swagger的请求成了一个问题。\n\n想到的方法一,用正则过滤：\n@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123;    @Override    protected void configure(HttpSecurity http) throws Exception &#123;        http.csrf().disable();        http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);        http.authorizeRequests()                .antMatchers(&quot;&#x2F;xxx&#x2F;!?(doc.html|v2&#x2F;api-docs|springfox.js|swagger-ui.html|swagger-resources|webjars)**&quot;).authenticated();        http.addFilterBefore(authenticationFilter(), UsernamePasswordAuthenticationFilter.class);        http.exceptionHandling().authenticationEntryPoint(new ComIdAuthenticationEntryPoint());    &#125;    &#x2F;&#x2F; ...&#125;\n\n更优雅的方法二，把Swagger的请求当做静态页面请求处理：\n@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123;    private List&lt;String&gt; PERMIT_URL_LIST &#x3D; ImmutableList.of(            &quot;&#x2F;xxx&#x2F;doc.html*&quot;,            &quot;&#x2F;xxx&#x2F;v2&#x2F;api-docs&#x2F;**&quot;,            &quot;&#x2F;xxx&#x2F;springfox.js*&quot;,            &quot;&#x2F;xxx&#x2F;swagger-ui.html*&quot;,            &quot;&#x2F;xxx&#x2F;swagger-resources&#x2F;**&quot;,            &quot;&#x2F;xxx&#x2F;webjars&#x2F;**&quot;);    @Override    protected void configure(HttpSecurity http) throws Exception &#123;        http.csrf().disable();        http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);        http.authorizeRequests()                .antMatchers(&quot;&#x2F;xxx&#x2F;**&quot;).authenticated();        http.addFilterBefore(authenticationFilter(), UsernamePasswordAuthenticationFilter.class);        http.exceptionHandling().authenticationEntryPoint(new ComIdAuthenticationEntryPoint());    &#125;    @Override    public void configure(WebSecurity web) throws Exception &#123;        web.ignoring().antMatchers(PERMIT_URL_LIST.toArray(new String[0]));    &#125;    &#x2F;&#x2F; ...&#125;\n","categories":["Spring"],"tags":[]},{"title":"日志归档工具logrotate介绍","url":"http://heqiao2010.github.io/2020/06/17/志归档工具logrotate介绍/","content":"缘起对于日志的归档，轮转以及清理，很多框架都已经支持，比如logback，log4j等，对于logrotate鲜有用武之地。\n不过最近做一个项目的时候，客户环境存在大量的syslog，但是对这类syslog日志确没有做定时的清理和归档，于是看了下centos自带的logrotate工具，还是蛮方便的。\n业务需求希望能够做到日志轮转，保留一周的日志，每天的日志保存到一个文件中，一周之前的日志，自动删除；2天之前的日志能够归档压缩；\n解决在/etc/logrotate.d/目录新增logrotate配置，例如：cat /etc/logrotate.d/test\n&#x2F;data&#x2F;log&#x2F;test.log &#123;        daily    #每天执行        missingok # 如果日志不存在，则忽略        rotate 7  # 保留7天的日志        create 644 root root  # 新创建文件权限        dateext  # 用日期作为文件名后缀        dateformat -%Y%m%d.%s #日期格式        nocompress  #不需要压缩，compress 表示用gzip压缩        copytruncate #采用拷贝后截断的方式，归档日志，好处是避免日志归档对正在写这个log的程序出现问题 &#125;\n\n\n参考文章https://blog.huoding.com/2013/04/21/246\nhttps://linux.die.net/man/8/logrotate\n","categories":["logrotate"],"tags":[]},{"title":"Freemarker中如何进行Json转化","url":"http://heqiao2010.github.io/2019/07/26/Freemarker中如何进行Json转化/","content":"缘起之前在开发过程中,freemarker的解析经常遇见一些问题,这里将这些问题做一下记录.\n比如,如下错误,是因为freemarker模板中出现了一个全角的中文空格,导致解析出现失败.\nError:(1, 1) java: 非法字符: &#39;\\ufeff&#39;\n\n需求需求是,从freemarker中构造出一个Json,然后将这个json进行url编码,放到一个url后面,用户点击这个url,则立即可以跳转到指定的页面,页面再根据这个参数做相应的解析.\n实现在freemarker中,是通过拼凑Json字段进行处理的.在拼凑Json字段的过程中,会涉及字段的转义:\nevent.params.group?j_string\n以及urlencode:\n&lt;#assign url_param&#x3D;&quot;search&#x3D;$&#123;search?url&#125;&quot; &#x2F;&gt;\n\n还有特别重要的是,有些字段需要判空,判空有好几种形式:\n&lt;#--条件判空--&gt;&lt;#if event.params.processName?? &gt;       \t\t     \t&lt;#assign processName &#x3D; event.params.processName?j_string &#x2F;&gt; &lt;&#x2F;#if&gt; &lt;#--感叹号判空--&gt;&lt;#assign filePath &#x3D; (event.params.filePath!&quot;&quot;)?j_string &#x2F;&gt;&lt;#--为空,则展示为空串--&gt;$&#123;(grouplist)!&#125;\n\n\n整体例子:\n&lt;#macro detailLinkParams aggregateAgentEvents&gt;        &lt;#setting url_escaping_charset&#x3D;&#39;utf8&#39;&#x2F;&gt;        &lt;#if (aggregateAgentEvents?size&gt;0) &gt; \t\t&lt;#--连接进程--&gt;\t\t&lt;#assign processName&#x3D;&quot;&quot; &#x2F;&gt;\t\t&lt;#--业务组--&gt;\t\t&lt;#assign group&#x3D;[] &#x2F;&gt;\t\t&lt;#--主机名--&gt;\t\t&lt;#assign hostname&#x3D;&quot;&quot; &#x2F;&gt;\t\t&lt;#--端口--&gt;\t\t&lt;#assign targetPort&#x3D;&quot;&quot; &#x2F;&gt;\t\t&lt;#--目标主机--&gt;\t\t&lt;#assign targetIpLike&#x3D;&quot;&quot; &#x2F;&gt;\t\t&lt;#--主机IP--&gt;\t\t&lt;#assign ip&#x3D;&quot;&quot; &#x2F;&gt;\t\t&lt;#--时间区间--&gt;\t\t&lt;#assign time_max &#x3D; aggregateAgentEvents[0].params.dataTime&#x2F;&gt;\t\t&lt;#assign time_min &#x3D; aggregateAgentEvents[0].params.dataTime&#x2F;&gt;                &lt;#list aggregateAgentEvents as event&gt; \t\t     &lt;#if event.params.group?? &amp;&amp; !(group?seq_contains(event.params.group?j_string)) &gt; \t\t     \t&lt;#assign group &#x3D; group + [event.params.group?j_string] &#x2F;&gt;\t\t     &lt;&#x2F;#if&gt; \t\t     &lt;#if event.params.processName?? &gt;       \t\t     \t&lt;#assign processName &#x3D; event.params.processName?j_string &#x2F;&gt; \t\t     &lt;&#x2F;#if&gt;         \t\t     &lt;#if event.params.hostname?? &gt;              \t\t     \t&lt;#assign hostname &#x3D; event.params.hostname?j_string &#x2F;&gt;  \t\t     &lt;&#x2F;#if&gt;\t\t     &lt;#if event.params.targetPort?? &gt;    \t\t     \t&lt;#assign targetPort &#x3D; event.params.targetPort?j_string &#x2F;&gt;\t\t     &lt;&#x2F;#if&gt;\t\t     &lt;#if event.params.targetIp?? &gt;    \t\t     \t&lt;#assign targetIpLike &#x3D; event.params.targetIp?j_string &#x2F;&gt;\t\t     &lt;&#x2F;#if&gt;\t\t     &lt;#if event.params.displayIp?? &gt;    \t\t     \t&lt;#assign ip &#x3D; event.params.displayIp?j_string &#x2F;&gt;\t\t     &lt;&#x2F;#if&gt;\t\t     &lt;#if (time_max &lt; event.params.dataTime) &gt;                            &lt;#assign time_max &#x3D; event.params.dataTime &#x2F;&gt;                     &lt;&#x2F;#if&gt;                     &lt;#if (time_min &gt; event.params.dataTime) &gt;                            &lt;#assign time_min &#x3D; event.params.dataTime &#x2F;&gt;                     &lt;&#x2F;#if&gt;                &lt;&#x2F;#list&gt;                &lt;#assign time_max &#x3D; time_max + 1&#x2F;&gt;\t\t&lt;#assign time_min &#x3D; time_min - 1&#x2F;&gt;                &lt;#assign time&#x3D;&quot;&#123;\\&quot;min\\&quot;:\\&quot;$&#123;(time_min*1000)?number_to_datetime?string(&#39;yyyy-MM-dd HH:mm:ss&#39;)&#125;\\&quot;,\\&quot;max\\&quot;:\\&quot;$&#123;(time_max*1000)?number_to_datetime?string(&#39;yyyy-MM-dd HH:mm:ss&#39;)&#125;\\&quot;&#125;&quot;&#x2F;&gt;                &lt;#assign grouplist &#x3D; group?join(&quot;,&quot;) &#x2F;&gt;\t\t&lt;#if (aggregateAgentEvents?size&#x3D;&#x3D;1) &gt;\t\t\t&lt;#assign search&#x3D;&quot;&#123;\\&quot;processName\\&quot;:\\&quot;$&#123;(processName)!&#125;\\&quot;,\\&quot;createTime\\&quot;:$&#123;time&#125;,\\&quot;group\\&quot;:[$&#123;(grouplist)!&#125;],\\&quot;ip\\&quot;:\\&quot;$&#123;(ip)!&#125;\\&quot;,\\&quot;targetIpLike\\&quot;:\\&quot;$&#123;(targetIpLike)!&#125;\\&quot;,\\&quot;targetPort\\&quot;:$&#123;(targetPort)!&#125;,\\&quot;hostname\\&quot;:\\&quot;$&#123;(hostname)!&#125;\\&quot;&#125;&quot;&#x2F;&gt;\t\t&lt;#else&gt;\t\t\t&lt;#assign search&#x3D;&quot;&#123;\\&quot;processName\\&quot;:\\&quot;$&#123;(processName)!&#125;\\&quot;,\\&quot;createTime\\&quot;:$&#123;time&#125;,\\&quot;group\\&quot;:[$&#123;(grouplist)!&#125;],\\&quot;ip\\&quot;:\\&quot;$&#123;(ip)!&#125;\\&quot;,\\&quot;targetIpLike\\&quot;:\\&quot;$&#123;(targetIpLike)!&#125;\\&quot;,\\&quot;targetPort\\&quot;:$&#123;(targetPort)!&#125;,\\&quot;hostname\\&quot;:\\&quot;$&#123;(hostname)!&#125;\\&quot;&#125;&quot;&#x2F;&gt;\t\t&lt;&#x2F;#if&gt;                &lt;#assign url_param&#x3D;&quot;search&#x3D;$&#123;search?url&#125;&quot; &#x2F;&gt;\t&lt;#else&gt;\t\t&lt;#assign url_param&#x3D;&quot;a&#x3D;1&quot;&#x2F;&gt;\t&lt;&#x2F;#if&gt;$&#123;url_param&#125;&lt;&#x2F;#macro&gt;\n\n额外的问题FreeMarker遍历集合集合时貌似有个要求，集合本身必须是Collection的子类；如果将jackson的JsonNode对象，扔给Freemarker则可能会有问题，例如：\n\t&#123;    &quot;vuls&quot;: [        &#123;            &quot;vuln&quot;: 1,            &quot;port&quot;: 6379,            &quot;title&quot;: &quot;xxx&quot;,            &quot;checkid&quot;: 7,            &quot;msg&quot;: &quot;xxx!&quot;,            &quot;hacked_file&quot;: [                &#123;                    &quot;info&quot;: &quot;xxx&quot;,                    &quot;path&quot;: &quot;xxx&quot;                &#125;            ],            &quot;pid&quot;: 1351        &#125;\t\t]&#125;\n\n如果通过如下模板进行解析，则会出现问题，因为json对象中的数组，无法用freemarker中的list遍历，这点很奇怪。\nXXX ：&lt;#list vuls as vul&gt; &lt;#list vul.hacked_file as item&gt;  xx：$&#123;item.path&#125;,xxx：$&#123;item.info&#125; &lt;&#x2F;#list&gt;&lt;&#x2F;#list&gt;\n\n但是可以通过把JsonNode当做字符串处理，在freemarker中用eval进行处理，则没问题：\n&lt;#function parseJSON json&gt;  &lt;#local null &#x3D; &#39;null&#39;&gt; &lt;#-- null is not a keyword in FTL --&gt;  &lt;#return json?eval&gt;&lt;&#x2F;#function&gt;&lt;#assign jsonObj&#x3D;parseJSON(vuls)&#x2F;&gt;XXX ：&lt;#list jsonObj as vul&gt; &lt;#list vul.hacked_file as item&gt;  xx：$&#123;item.path&#125;,xxx：$&#123;item.info&#125; &lt;&#x2F;#list&gt;&lt;&#x2F;#list&gt;\n\n参考资料https://stackoverflow.com/questions/46154391/how-can-i-iterate-a-collection-twice-in-freemarker#\nhttps://stackoverflow.com/questions/17778844/evaluate-json-with-null-value-using-freemarker\nhttps://stackoverflow.com/questions/12708162/how-to-get-json-into-a-freemarker-template-ftl\n","categories":["Freemarker"],"tags":["Freemarker"]},{"title":"ControllerAdvice注解","url":"http://heqiao2010.github.io/2019/07/08/ControllerAdvice注解/","content":"基本功能准确的来说,这个是springmvc中的一个注解.从Advice后缀可以看出,这个注解是针对Controller的一个增强.在对外提供Http接口支持的时候,往往有很多通用的业务逻辑.最常见的是同样的异常处理逻辑.为了避免大块的try-catch块的出现,可以通过此注解提供一个异常处理的增强来解决.\n@ExceptionHandler在ControllerAdvice类中标注某个方法,用于处理某个类型的异常.\n例子:\n&#x2F;** * 统一处理网关接口异常 * * Created by qiaohe on 19-6-27. *&#x2F;@Component@ControllerAdvice(&quot;com.*&quot;)public class ExceptionAdvice &#123;    private final Logger logger &#x3D; LoggerFactory.getLogger(ExceptionAdvice.class);    &#x2F;**     * 处理AuthFailedException     *&#x2F;    @ExceptionHandler(AuthFailedException.class)    @ResponseBody    public BaseResult handleException(AuthFailedException ex)&#123;        return BaseResult.failure(ex.getAuthFailedCode().getCode(),                ex.getAuthFailedCode().getDesc());    &#125;&#125;\n\n其他两个不常用的注解@InitBinder：用来设置WebDataBinder，用于自动绑定前台请求参数到Model中。\n@ModelAttribute：本来作用是绑定键值对到Model中，此处让全局的@RequestMapping都能获得在此处设置的键值对。\n列子:\n@ControllerAdvice(basePackages &#x3D; &#123;&quot;com.concretepage.controller&quot;&#125; )public class GlobalControllerAdvice &#123;\t@InitBinder\tpublic void dataBinding(WebDataBinder binder) &#123;\t\tSimpleDateFormat dateFormat &#x3D; new SimpleDateFormat(&quot;dd&#x2F;MM&#x2F;yyyy&quot;);\t\tdateFormat.setLenient(false);\t\tbinder.registerCustomEditor(Date.class, &quot;dob&quot;, new CustomDateEditor(dateFormat, true));\t&#125;\t@ModelAttribute        public void globalAttributes(Model model) &#123;\t\tmodel.addAttribute(&quot;msg&quot;, &quot;Welcome to My World!&quot;);        &#125;\t@ExceptionHandler(FileNotFoundException.class)        public ModelAndView myError(Exception exception) &#123;\t    ModelAndView mav &#x3D; new ModelAndView();\t    mav.addObject(&quot;exception&quot;, exception);\t    mav.setViewName(&quot;error&quot;);\t    return mav;\t&#125;&#125; \n\n参考https://www.concretepage.com/spring/spring-mvc/spring-mvc-controlleradvice-annotation-example\n","categories":["Spring"],"tags":["Spring"]},{"title":"Spring学习之Profile和Lookup注解","url":"http://heqiao2010.github.io/2019/07/02/Spring学习之Profile和Lookup注解/","content":"\n在编码过程中遇到一个Profile和Lookup注解的问题,这里记录一下.Profile的原意是剖面的意思,Profile在官方的API文档中,是如此描述的:\n\n\nA profile is a named logical grouping that may be activated programmatically via ConfigurableEnvironment.setActiveProfiles(java.lang.String…) or declaratively by setting the spring.profiles.active property as a JVM system property, as an environment variable, or as a Servlet context parameter in web.xml for web applications. Profiles may also be activated declaratively in integration tests via the @ActiveProfiles annotation.\n\n\n通过Profile可以从逻辑上对Bean做一些分组,然后应用中通过配置来选中某一组Bean进行实例化.Lookup注解是用于实现,注入prototype-scoped类型的Bean,一般我们可能习惯用new的方式去实例化非单例模式的Bean.\n\nProfile注解示例实现开发环境和生产环境采用不同的数据源.\n&#x2F;&#x2F; 开发环境采用mysql数据库@Profile(&quot;Development&quot;)@Configurationpublic class DevDatabaseConfig implements DatabaseConfig &#123;     @Override    @Bean    public DataSource createDataSource() &#123;        System.out.println(&quot;Creating DEV database&quot;);        DriverManagerDataSource dataSource &#x3D; new DriverManagerDataSource();        &#x2F;*         * Set MySQL specific properties for Development Environment         *&#x2F;        return dataSource;    &#125; &#125;&#x2F;&#x2F; 生产环境采用Oracle数据库@Profile(&quot;Production&quot;)@Configurationpublic class ProductionDatabaseConfig implements DatabaseConfig &#123;     @Override    @Bean    public DataSource createDataSource() &#123;        System.out.println(&quot;Creating Production database&quot;);        DriverManagerDataSource dataSource &#x3D; new DriverManagerDataSource();        &#x2F;*         * Set ORACLE specific properties for Production environment         *&#x2F;        return dataSource;    &#125; &#125;\n\n除了采用注解,使用配置文件也可以达到同样的效果.\n&lt;beans profile&#x3D;&quot;Development&quot;&gt;    &lt;import resource&#x3D;&quot;dev-config-context.xml&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; &lt;beans profile&#x3D;&quot;Production&quot;&gt;    &lt;import resource&#x3D;&quot;prod-config-context.xml&quot;&#x2F;&gt;&lt;&#x2F;beans&gt;\n\n测试:\npublic class AppMain &#123;         public static void main(String args[])&#123;        AnnotationConfigApplicationContext  context &#x3D; new AnnotationConfigApplicationContext();        &#x2F;&#x2F;Sets the active profiles        context.getEnvironment().setActiveProfiles(&quot;Development&quot;);        &#x2F;&#x2F;Scans the mentioned package[s] and register all the @Component available to Spring        context.scan(&quot;com.websystique.spring&quot;);         context.refresh();        context.close();    &#125; &#125;\n\nLookup注解lookup可以实现方法注入,即利用lookup可以让某个单例Bean的某个方法每次都返回一个新的Bean,即prototype类型的Bean.这是依赖CGlib技术实现的,在运行时,修改字节码.\n利用xml文件实现:\n&lt;bean id&#x3D;&quot;car&quot; class&#x3D;&quot;com.smart.injectfun.Car&quot; p:brand&#x3D;&quot;红旗CA72&quot;, p:price&#x3D;&quot;2000&quot; scope&#x3D;&quot;prototype&quot; &#x2F;&gt;&lt;bean id&#x3D;&quot;magicBoss&quot; class&#x3D;&quot;com.smart.injectfun.MagicBoss&quot;&gt;    &lt;look-method name&#x3D;&quot;getCar&quot; bean&#x3D;&quot;car&quot;&gt;&lt;bean&gt;\n\n也可以通过注解来实现:\n@Componentpublic class MagicBossIMpl implements MagicBoss &#123;    @Lookup    public Car getCar()&#123;        return null;    &#125;&#125;\n\n参考https://www.baeldung.com/spring-lookup\nhttp://websystique.com/spring/spring-profile-example/\n","categories":["Spring"],"tags":["Spring"]},{"title":"Java诊断工具Arthas之watch命令","url":"http://heqiao2010.github.io/2019/07/01/Java诊断工具Arthas之watch命令/","content":"\nArthas是一个开源的Java诊断工具,详见:https://alibaba.github.io/arthas/index.html. 今天第一次在项目中排查问题使用到它,发现其功能确实很强大.这里记录一下watch命令的使用.\n\n安装安装JDK然后以jar包的形式运行即可.\nwget https:&#x2F;&#x2F;alibaba.github.io&#x2F;arthas&#x2F;arthas-boot.jarjava -jar arthas-boot.jar\n\n利用watch诊断方法调用通过Arthas的watch方法可以在没有打印日志的情况下,看到方法的入参和返回值.这点在没有打印debug或者重启会破坏现场的情况下是非常有用的。\n在运行arthas-boot.jar之后，会列出当前系统中的所有java进程，然后输入需要诊断的进程的序号，就进入了arthas的命令模式了。这里以官网上的java -jar arthas-demo.jar为例，毕竟为了信息安全，把在公司的debug信息透出不大好。\n\n首先可以利用sc命令，查询对应的类名。\n$ sc *Math*demo.MathGameio.netty.util.internal.MathUtiljava.lang.MathAffect(row-cnt:3) cost in 17 ms.\n\n然后再用sm命令，查询对应的方法。\n$ sm demo.MathGame*demo.MathGame &lt;init&gt;()Vdemo.MathGame primeFactors(I)Ljava&#x2F;util&#x2F;List;demo.MathGame main([Ljava&#x2F;lang&#x2F;String;)Vdemo.MathGame run()Vdemo.MathGame print(ILjava&#x2F;util&#x2F;List;)VAffect(row-cnt:5) cost in 9 ms.\n\n利用watch命令，监听指定的方法，-x 参数可以指定打印入参和返回值的深度。\n\n\n$ watch demo.MathGame primeFactors &quot;&#123;params,returnObj&#125;&quot; -x 2Press Q or Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 49 ms.ts&#x3D;2019-07-03 14:29:41; [cost&#x3D;1.778091ms] result&#x3D;@ArrayList[    @Object[][        @Integer[-136776],    ],    null,]ts&#x3D;2019-07-03 14:29:42; [cost&#x3D;0.105508ms] result&#x3D;@ArrayList[    @Object[][        @Integer[47524],    ],    @ArrayList[        @Integer[2],        @Integer[2],        @Integer[109],        @Integer[109],    ],]\n我就是利用这个工具，诊断出系统中一个很奇怪的问题。最终原因是因为PHP程序调用Java接口在时序上有略微的差异导致的。\n","categories":["Arthas"],"tags":["Arthas"]},{"title":"JUC共享锁之Semaphore","url":"http://heqiao2010.github.io/2019/06/24/JUC共享锁之Semaphore/","content":"\nSemaphore原意是指信号量,从API的注释:”Semaphores are often used to restrict the number of threads than can access some (physical or logical) resource”可以看出,Semaphore一般是用来限制线程能够使用的资源个数.\n\n应用场景在Web开发中,Semaphore可以用来限制某个接口的并发调用次数.可以在Sping的Context中维护一个Map,key可以是处理线程,value可以是一个Semaphore对象.通过这样的方式,就可以实现系统同时处理的线程数不会超过某个阈值.\n代码实现我们可以通过WebFilter注解,来实现一个过滤器,在过滤器中拦截所有的请求调用,然后通过Semaphore来进行计数,如果超过总的计数,则返回相应的提示信息.当然也可以对URL进行细化,针对每个API提供对应的限制.\n&#x2F;** * API并发控制过滤器 * Created by qiaohe * Date: 19-7-1 上午11:54 *&#x2F;@Component@WebFilter(urlPatterns &#x3D; &quot;&#x2F;*&quot;, filterName &#x3D; &quot;concurrentRestrictFilter&quot;)public class ConcurrentRestrictFilter implements Filter &#123;    private Log log &#x3D; LogFactory.getLog(getClass());    private static final Integer MAX_CONCURRENT_NUM &#x3D; 1;    private static final Semaphore semaphore &#x3D; new Semaphore(MAX_CONCURRENT_NUM);    @Override    public void init(FilterConfig filterConfig) throws ServletException &#123;    &#125;    @Override    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;        log.info(&quot;before acquire: &quot; + semaphore.availablePermits());        if(!semaphore.tryAcquire())&#123;            if(response instanceof HttpServletResponse)&#123;                HttpServletResponse res &#x3D; (HttpServletResponse)response;                res.setContentType(MimeTypeUtils.APPLICATION_JSON_VALUE);                res.sendError(HttpStatus.BAD_REQUEST.value(), &quot;reach max current num&quot;);            &#125;            return;        &#125;        log.info(&quot;after acquire: &quot; + semaphore.availablePermits());        try&#123;            chain.doFilter(request, response);        &#125; finally &#123;            semaphore.release();            log.info(&quot;release: &quot; + semaphore.availablePermits());        &#125;    &#125;    @Override    public void destroy() &#123;    &#125;&#125;\n","categories":["Java并发基础"],"tags":["Java"]},{"title":"如何将jar包发布到中央仓库","url":"http://heqiao2010.github.io/2019/06/21/如何将jar包发布到中央仓库/","content":"\n之前在github上开发了一个简单的项目，一直想把这个jar包发布到中央仓库。一直没有时间弄这个，今天抽出点时间，按照网上的例子，操作了一遍，顺便记录一下，一遍将来参考。我的开发环境是ubuntu18.04，maven3，整个过程还是比较顺利的。\n\n注册JIRA账号打开https://issues.sonatype.org/secure/Dashboard.jspa ，用邮箱注册即可。\n创建issue需要填写group id项目地址之类的，页面都有示例提示。\n等待审核提交的issue需要人工审核，审核之后，issue的状态变为：RESOLVED，到了这一步就可以上传jar包了。\n配置maven Setting.xml文件maven的Setting.xml文件可以在安装路径的conf目录下，也可以只修改当前用户.m目录下，如果你的电脑是多账户共享的话。在Settings.xml文件中，找到&lt;servers&gt;标签，然后在标签中增加如下配置：\n&lt;server&gt;    &lt;id&gt;自行替换&lt;&#x2F;id&gt;    &lt;username&gt;替换成自己的JIRA账号&lt;&#x2F;username&gt;    &lt;password&gt;替换成自己的JIRA账号密码&lt;&#x2F;password&gt;&lt;&#x2F;server&gt;\nid一般写oss就行。需要和pom文件中保持一致。\n修改pom文件我这次发布的pom文件内容如下：\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot;         xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;         xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.sonatype.oss&lt;&#x2F;groupId&gt;        &lt;artifactId&gt;oss-parent&lt;&#x2F;artifactId&gt;        &lt;version&gt;7&lt;&#x2F;version&gt;    &lt;&#x2F;parent&gt;    &lt;licenses&gt;        &lt;license&gt;            &lt;name&gt;The Apache Software License, Version 2.0&lt;&#x2F;name&gt;            &lt;url&gt;http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0.txt&lt;&#x2F;url&gt;            &lt;distribution&gt;repo&lt;&#x2F;distribution&gt;        &lt;&#x2F;license&gt;    &lt;&#x2F;licenses&gt;    &lt;scm&gt;        &lt;url&gt;https:&#x2F;&#x2F;github.com&#x2F;heqiao2010&lt;&#x2F;url&gt;        &lt;connection&gt;https:&#x2F;&#x2F;github.com&#x2F;heqiao2010&#x2F;LunarCalendar.git&lt;&#x2F;connection&gt;    &lt;&#x2F;scm&gt;    &lt;developers&gt;        &lt;developer&gt;            &lt;name&gt;Joel Herb&lt;&#x2F;name&gt;            &lt;email&gt;he_qiao_2010@yeah.net&lt;&#x2F;email&gt;            &lt;organization&gt;heqiao2010&lt;&#x2F;organization&gt;        &lt;&#x2F;developer&gt;    &lt;&#x2F;developers&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt;    &lt;&#x2F;properties&gt;    &lt;groupId&gt;com.github.heqiao2010&lt;&#x2F;groupId&gt;        &lt;artifactId&gt;lunar&lt;&#x2F;artifactId&gt;    &lt;version&gt;1.0&lt;&#x2F;version&gt;    &lt;name&gt;LunarCalendar&lt;&#x2F;name&gt;    &lt;description&gt;A Java implementation of Chinese lunar calendar. &lt;&#x2F;description&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;            &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;            &lt;version&gt;4.12&lt;&#x2F;version&gt;            &lt;scope&gt;test&lt;&#x2F;scope&gt;        &lt;&#x2F;dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.google.code.gson&lt;&#x2F;groupId&gt;            &lt;artifactId&gt;gson&lt;&#x2F;artifactId&gt;            &lt;version&gt;2.8.5&lt;&#x2F;version&gt;            &lt;scope&gt;test&lt;&#x2F;scope&gt;        &lt;&#x2F;dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.httpcomponents&lt;&#x2F;groupId&gt;            &lt;artifactId&gt;httpclient&lt;&#x2F;artifactId&gt;            &lt;version&gt;4.5.7&lt;&#x2F;version&gt;            &lt;scope&gt;test&lt;&#x2F;scope&gt;        &lt;&#x2F;dependency&gt;    &lt;&#x2F;dependencies&gt;    &lt;profiles&gt;        &lt;profile&gt;            &lt;id&gt;release&lt;&#x2F;id&gt;            &lt;build&gt;                &lt;plugins&gt;                    &lt;!-- Source --&gt;                    &lt;plugin&gt;                        &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;                        &lt;artifactId&gt;maven-source-plugin&lt;&#x2F;artifactId&gt;                        &lt;version&gt;2.2.1&lt;&#x2F;version&gt;                        &lt;executions&gt;                            &lt;execution&gt;                                &lt;phase&gt;package&lt;&#x2F;phase&gt;                                &lt;goals&gt;                                    &lt;goal&gt;jar-no-fork&lt;&#x2F;goal&gt;                                &lt;&#x2F;goals&gt;                            &lt;&#x2F;execution&gt;                        &lt;&#x2F;executions&gt;                    &lt;&#x2F;plugin&gt;                    &lt;!-- Javadoc --&gt;                    &lt;plugin&gt;                        &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;                        &lt;artifactId&gt;maven-javadoc-plugin&lt;&#x2F;artifactId&gt;                        &lt;version&gt;2.9.1&lt;&#x2F;version&gt;                        &lt;executions&gt;                            &lt;execution&gt;                                &lt;phase&gt;package&lt;&#x2F;phase&gt;                                &lt;goals&gt;                                    &lt;goal&gt;jar&lt;&#x2F;goal&gt;                                &lt;&#x2F;goals&gt;                            &lt;&#x2F;execution&gt;                        &lt;&#x2F;executions&gt;                    &lt;&#x2F;plugin&gt;                    &lt;!-- GPG --&gt;                    &lt;plugin&gt;                        &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;                        &lt;artifactId&gt;maven-gpg-plugin&lt;&#x2F;artifactId&gt;                        &lt;version&gt;1.6&lt;&#x2F;version&gt;                        &lt;executions&gt;                            &lt;execution&gt;                                &lt;phase&gt;verify&lt;&#x2F;phase&gt;                                &lt;goals&gt;                                    &lt;goal&gt;sign&lt;&#x2F;goal&gt;                                &lt;&#x2F;goals&gt;                            &lt;&#x2F;execution&gt;                        &lt;&#x2F;executions&gt;                    &lt;&#x2F;plugin&gt;                &lt;&#x2F;plugins&gt;            &lt;&#x2F;build&gt;            &lt;distributionManagement&gt;                &lt;snapshotRepository&gt;                    &lt;id&gt;oss&lt;&#x2F;id&gt;                    &lt;url&gt;https:&#x2F;&#x2F;oss.sonatype.org&#x2F;content&#x2F;repositories&#x2F;snapshots&#x2F;&lt;&#x2F;url&gt;                &lt;&#x2F;snapshotRepository&gt;                &lt;repository&gt;                    &lt;id&gt;oss&lt;&#x2F;id&gt;                    &lt;url&gt;https:&#x2F;&#x2F;oss.sonatype.org&#x2F;service&#x2F;local&#x2F;staging&#x2F;deploy&#x2F;maven2&#x2F;&lt;&#x2F;url&gt;                &lt;&#x2F;repository&gt;            &lt;&#x2F;distributionManagement&gt;        &lt;&#x2F;profile&gt;    &lt;&#x2F;profiles&gt;&lt;&#x2F;project&gt;\n\n生成并上传密钥运行如下命令，根据提示生成密钥，需要设置pharse。\ngpg --gen-key\n生成的密钥类似：\n➜  ~ gpg --list-keys &#x2F;home&#x2F;qiaohe&#x2F;.gnupg&#x2F;pubring.gpg-------------------------------pub   rsa3072 2019-06-21 [SC] [有效至：2021-06-20]      812FAC0448CBA6C3E8EA8EA67BA82CF4A21310B2uid           [ 绝对 ] Joel Herb &lt;he_qiao_2010@yeah.net&gt;sub   rsa3072 2019-06-21 [E] [有效至：2021-06-20]\n然后上传密钥：\ngpg --keyserver hkp:&#x2F;&#x2F;keyserver.ubuntu.com:11371 --send-keys 812FAC0448CBA6C3E8EA8EA67BA82CF4A21310B2\n\n执行部署mvn clean deploy -P release\n-P命令用于指定pom文件中profile的id。在编译之后，上传到中央服务器的时候，系统会提示让你输入密钥中的phrase，如果是windows系统可以在编译命令后加上-Dgpg.passphrase=设置的pharse\n上传完成之后在https://oss.sonatype.org （登陆账号和新建issue的账号一致）这个页面的staging repositories页签中可以看到刚才上传的内容，默认是open状态的，先点击上方的close然后再点击release即可。注意relesea版本的jar中的版本号不能带SNAPSHOT字样，因为SNAPSHOT版本是不稳定版，不应该release，否则会有歧义，容易引起误解。\n通知管理员在之前创建的issue下，评论通知管理员，已经上传jar包了。等管理员操作之后，在中央仓库就可以看到上传的jar包了。例如：\n&lt;dependency&gt;  &lt;groupId&gt;com.github.heqiao2010&lt;&#x2F;groupId&gt;  &lt;artifactId&gt;lunar&lt;&#x2F;artifactId&gt;  &lt;version&gt;1.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;\n参考https://blog.csdn.net/ljbmxsm/article/details/78009268\n","categories":["git"],"tags":["Maven"]},{"title":"Freemarker中如何避免xss漏洞","url":"http://heqiao2010.github.io/2019/06/20/Freemarker中如何避免xss漏洞/","content":"什么是XSS漏洞试想一下，如果我们开发一个订单系统，订单名称如果没有做限制，允许用户输入任意字符，那么就有产生XSS的危险。攻击者可以很容易编写一个恶意JS脚本,然后将当前登录用户的cookie或者其他敏感信息抓取到，发送给攻击者自己，这就是XSS（跨站脚本）攻击。如何解决这个问题，首先我们想到的是在用户输入订单的时候，我们对订单名称做限制，不允许输入特殊字符。这样是可以避免的，不过对于一个大的系统来说，用户可以输入的字段太多了，如果能够全部校验，是最好的。如果不能做的话，还可以让前端在做展示的时候进行html转义处理一下，这样原本scirpt标签以及当中的内容就被当做一个字符串展示出来，而不是当做代码执行了。一般现在的reactjs等前端框架已经默认支持防xss了。今天我遇到的问题是，有一部分freemarker写的页面存在XSS的问题。\nFreeMarker中解决XSS可以通过对用户输入的字段进行html转义，来有效的避免XSS问题。freemarker模板中的变量通过${value}这样的形式引入，但是挨个修改成$&#123;value?html&#125;的形式未免工作量太大；查阅官方文档，通过escape标签可以对整个模板中$号引入的变量全部进行一次html转义。比如：\n&lt;#assign x &#x3D; &quot;&lt;test&gt;&quot;&gt;&lt;#macro m1&gt;  m1: $&#123;x&#125;&lt;&#x2F;#macro&gt;&lt;#escape x as x?html&gt;  &lt;#macro m2&gt;m2: $&#123;x&#125;&lt;&#x2F;#macro&gt;  $&#123;x&#125;  &lt;@m1&#x2F;&gt;&lt;&#x2F;#escape&gt;$&#123;x&#125;&lt;@m2&#x2F;&gt;\n会输出：\n  &lt;test&gt;  m1: &lt;test&gt;&lt;test&gt;m2: &lt;test&gt;\n\n这种方式完全满足现在的改造需求。在这个项目中，freemarker模板是存储在数据库中，所有用到freemarker渲染的地方均是用的同一个入口；这样工作量就不大了。我们知道，freemarker加载模板是通过TemplateLoader这个接口来实现的；只需要在加载模板的时候在模板的头部加上&lt;#escape x as x?html&gt;在尾部加上&lt;/#escape就可以对模板中所有的变量进行html转义了。通过这种方式数据库中的数据也不用修改，将来生成模板，也不需要考虑做html转义的问题。\npublic interface TemplateLoader &#123;\t    public Object findTemplateSource(String name)    throws IOException;    public long getLastModified(Object templateSource);      public Reader getReader(Object templateSource, String encoding) throws IOException;     public void closeTemplateSource(Object templateSource) throws IOException;    &#125;\n由于实现逻辑还是从外部读取字符串加载，所以TemplateLoader接口支持html转义的实现和StringTemplateLoader的逻辑差不多。\npublic class HtmlEscapeTemplateLoader implements TemplateLoader &#123;    private static final String HTML_ESCAPE_PREFIX &#x3D; &quot;&lt;#escape x as x?html&gt;&quot;;    private static final String HTML_ESCAPE_SUFFIX &#x3D; &quot;&lt;&#x2F;#escape&gt;&quot;;    &#x2F;&#x2F; 为了支持并发，这里采用ConcurrentMap    private final Map&lt;String, StringTemplateSource&gt; templates &#x3D; Maps.newConcurrentMap();    public void putTemplate(String name, String templateContent) &#123;        putTemplate(name, templateContent, System.currentTimeMillis());    &#125;    public void putTemplate(String name, String templateContent, long lastModified) &#123;        templates.put(name, new HtmlEscapeTemplateLoader.StringTemplateSource(name, templateContent, lastModified));    &#125;    public boolean removeTemplate(String name) &#123;        return templates.remove(name) !&#x3D; null;    &#125;    public void closeTemplateSource(Object templateSource) &#123;    &#125;    public Object findTemplateSource(String name) &#123;        return templates.get(name);    &#125;    public long getLastModified(Object templateSource) &#123;        return ((HtmlEscapeTemplateLoader.StringTemplateSource) templateSource).lastModified;    &#125;    public Reader getReader(Object templateSource, String encoding) throws IOException &#123;        Reader reader &#x3D; new StringReader(((StringTemplateSource) templateSource).templateContent);        String templateText &#x3D; IOUtils.toString(reader);        return new StringReader(HTML_ESCAPE_PREFIX + templateText + HTML_ESCAPE_SUFFIX);    &#125;    private static class StringTemplateSource &#123;        private final String name;        private final String templateContent;        private final long lastModified;        StringTemplateSource(String name, String templateContent, long lastModified) &#123;            if (name &#x3D;&#x3D; null) &#123;                throw new IllegalArgumentException(&quot;name &#x3D;&#x3D; null&quot;);            &#125;            if (templateContent &#x3D;&#x3D; null) &#123;                throw new IllegalArgumentException(&quot;source &#x3D;&#x3D; null&quot;);            &#125;            if (lastModified &lt; -1L) &#123;                throw new IllegalArgumentException(&quot;lastModified &lt; -1L&quot;);            &#125;            this.name &#x3D; name;            this.templateContent &#x3D; templateContent;            this.lastModified &#x3D; lastModified;        &#125;        @Override        public int hashCode() &#123;            final int prime &#x3D; 31;            int result &#x3D; 1;            result &#x3D; prime * result + ((name &#x3D;&#x3D; null) ? 0 : name.hashCode());            return result;        &#125;        @Override        public boolean equals(Object obj) &#123;            if (this &#x3D;&#x3D; obj)                return true;            if (obj &#x3D;&#x3D; null)                return false;            if (getClass() !&#x3D; obj.getClass())                return false;            HtmlEscapeTemplateLoader.StringTemplateSource other &#x3D; (HtmlEscapeTemplateLoader.StringTemplateSource) obj;            if (name &#x3D;&#x3D; null) &#123;                if (other.name !&#x3D; null)                    return false;            &#125; else if (!name.equals(other.name))                return false;            return true;        &#125;        @Override        public String toString() &#123;            return name;        &#125;    &#125;    &#x2F;**     * Show class name and some details that are useful in template-not-found errors.     *     * @since 2.3.21     *&#x2F;    @Override    public String toString() &#123;        StringBuilder sb &#x3D; new StringBuilder();        sb.append(getClassNameForToString(this));        sb.append(&quot;(Map &#123; &quot;);        int cnt &#x3D; 0;        for (String name : templates.keySet()) &#123;            cnt++;            if (cnt !&#x3D; 1) &#123;                sb.append(&quot;, &quot;);            &#125;            if (cnt &gt; 10) &#123;                sb.append(&quot;...&quot;);                break;            &#125;            sb.append(StringUtil.jQuote(name));            sb.append(&quot;&#x3D;...&quot;);        &#125;        if (cnt !&#x3D; 0) &#123;            sb.append(&#39; &#39;);        &#125;        sb.append(&quot;&#125;)&quot;);        return sb.toString();    &#125;    private static String getClassNameForToString(TemplateLoader templateLoader) &#123;        final Class tlClass &#x3D; templateLoader.getClass();        final Package tlPackage &#x3D; tlClass.getPackage();        return tlPackage &#x3D;&#x3D; Configuration.class.getPackage() || tlPackage &#x3D;&#x3D; TemplateLoader.class.getPackage()                ? tlClass.getSimpleName() : tlClass.getName();    &#125;&#125;\n至此实现了在freemarker中自动进行html转义避免XSS问题的过程。参考网上有些资料可以修改freemarker的源码，对其在进行$号解析的时候，自动加上html转义的逻辑，也是可以的。如果某些特殊情况下，就是需要展示html形式的内容而不需要转义，或者有人错误的将变量进行了一次转义比如写成$&#123;!(value)?html&#125;的形式，会怎样？\n如果就是需要展示html形式的内容而不需要转义，可以用&lt;#noescape&gt;标签将不需要转义的变量包裹起来，这样就算外层有&lt;#escape&gt;也不会进行转义了。如果在外部有&lt;#escape&gt;的情况下，变量自身又做了一次转义，那么该变量会被转义两次。正常字符不会有影响，含有特殊字符的话，可能比较难看了。\n参考https://blog.csdn.net/shadowsick/article/details/80768868https://my.oschina.net/greki/blog/83246?p=1\n","categories":["Freemarker"],"tags":["Freemarker"]},{"title":"VirtualBox虚拟机和宿主机实现网络互通配置","url":"http://heqiao2010.github.io/2019/06/19/VirtualBox虚拟机和宿主机实现网络互通配置/","content":"\n由于想要在本地测试一下syslog以及安装jenkins等需求，所以想在本地安装一个虚拟机，并且能够在宿主机上访问，所以想利于virtualbox上安装一个linux来实现，尝试了几次，其实配置挺简单的，这里记录一下。\n\n接入方式对比VirtualBox的提供了四种网络接入模式\n\nNAT 网络地址转换模式(NAT,Network Address Translation) ：宿主机做nat转换，对外外部网络来说，虚拟机是不可见的，因为宿主机代理了虚拟机的所有请求。\nBridged Adapter 桥接模式 ：对于虚拟机，外部网络可见，虚拟机和宿主机存在于同一个网段。\nInternal 内部网络模式 ：创建一个隔离的虚拟网络，在这个网络中的虚拟机之间可以相互访问，虚拟机不能访问外部网络，外部网络也不能访问内部虚拟机。\nHost-only Adapter 主机模式 ：　也可以通过配置实现，下次有机会再看看。\n\n各个接入方式对比：\n\n\n\n\nNAT\nBridged\nInternal\nHost-only\n\n\n\n虚拟机－&gt;宿主机\n√\n√\n×\n默认不能，需设置\n\n\n宿主机－&gt;虚拟机\n×\n√\n×\n默认不能，需设置\n\n\n虚拟机－&gt;其他主机\n√\n√\n×\n默认不能，需设置\n\n\n其他主机－&gt;宿主机\n×\n√\n×\n默认不能，需设置\n\n\n虚拟机之间\n×\n√\n同网络名下可以\n√\n\n\n配置从对比中可以看出桥接方式是最优的方案，但是配置之后，宿主机和虚拟机之间能够互通，但是在虚拟机中不能上外网了，因为配置的宿主机DNS不能解析外部域名，而虚拟机中也无法ping通诸如114.114.114.114的地址。\n如果做NAT的话，虚拟机是可以访问外网的，所以可以给虚拟机设置两个网卡。一个做桥接一个做NAT就达到目的了。\n\n需要注意的是桥接网卡在虚拟机中需要手动配置一个和宿主机同网段的IP，网关和DNS最好和宿主机配置一致。\n参考https://blog.csdn.net/chaishen10000/article/details/82984811\n","categories":["虚拟机"],"tags":["VirtualBox"]},{"title":"记一次重写RequestMappingHandlerMapping的经历","url":"http://heqiao2010.github.io/2019/06/17/一次重写RequestMappingHandlerMapping的经历/","content":"\n近期公司的产品做了一次安全审查，发现后端提供的接口有不安全的Http方法漏洞。不安全的HTTP方法一般包括：TRACE、PUT、DELETE、COPY 等。其中最常见的为TRACE方法可以回显服务器收到的请求，主要用于测试或诊断，恶意攻击者可以利用该方法进行跨站跟踪攻击（即XST攻击），从而进行网站钓鱼、盗取管理员cookie等。\n\n原因分析引起这个问题的原因其实很简单，因为开发人员开发接口的时候偷懒没有指定RequestMapping中的method属性导致的。没有指定method则系统会默认支持除了TRACE之外的其他７中方式，所以，这就是我要重写的RequestMappingHandlerMapping原因。\n当然还有其他的方式，比如搜索出所有采用RequestMapping而没有指定method的地方，然后在代码中明确指定method。这种方式思路最简单，但是毕竟人是懒惰的。而且将来代码开发中如果任然有人不指定method，那么这个问题任然会存在。所以我们需要改动一下，框架加载http接口映射关系的逻辑：\n在没有指定method的情况下，只支持GET和POST；在明确指定method的情况下，保留指定的method。\n为什么重写的是RequestMappingHandlerMapping首先后端提供的Http请求均是通过RestController和RequestMapping(或者衍生的GetMapping/PostMapping等)来实现的。那在接收http请求之后，如何将http请求映射到具体的Controller中的方法上呢？答案在HandlerMapping这个接口。这个具体映射过程细节以后再说，而HandlerMapping接口的映射方法getHandler是在AbstractHandlerMapping中实现的，而AbstractHandlerMapping的一个非抽象子类就是RequestMappingHandlerMapping。\n重写RequestMappingHandlerMapping的哪个方法从RequestMappingHandlerMapping中的getMappingForMethod方法可以看出，接口的映射信息，是由两部分组成的。一部分是来自于Controller类上的RequestMapping注解，一部分是来自于方法上的RequestMapping注解。所以，在这个方法中createRequestMappingInfo调用了两次，然后再组合。\n@Override\tprotected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123;\t\tRequestMappingInfo info &#x3D; createRequestMappingInfo(method);\t\tif (info !&#x3D; null) &#123;\t\t\tRequestMappingInfo typeInfo &#x3D; createRequestMappingInfo(handlerType);\t\t\tif (typeInfo !&#x3D; null) &#123;\t\t\t\tinfo &#x3D; typeInfo.combine(info);\t\t\t&#125;\t\t&#125;\t\treturn info;\t&#125;\n\n真正的createRequestMappingInfo有一个代理方法。\nprivate RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123;\t\tRequestMapping requestMapping &#x3D; AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class);\t\tRequestCondition&lt;?&gt; condition &#x3D; (element instanceof Class ?\t\t\t\tgetCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element));\t\treturn (requestMapping !&#x3D; null ? createRequestMappingInfo(requestMapping, condition) : null);\t&#125;\n\n在createRequestMappingInfo中，找到我们想要改动的地方了。在RequestMappingInfo设置method的时候增加一段自己的逻辑即可。\nprotected RequestMappingInfo createRequestMappingInfo(\t\t\tRequestMapping requestMapping, RequestCondition&lt;?&gt; customCondition) &#123;\t\treturn RequestMappingInfo\t\t\t\t.paths(resolveEmbeddedValuesInPatterns(requestMapping.path()))\t\t\t\t.methods(requestMapping.method())\t\t\t\t.params(requestMapping.params())\t\t\t\t.headers(requestMapping.headers())\t\t\t\t.consumes(requestMapping.consumes())\t\t\t\t.produces(requestMapping.produces())\t\t\t\t.mappingName(requestMapping.name())\t\t\t\t.customCondition(customCondition)\t\t\t\t.options(this.config)\t\t\t\t.build();\t&#125;\n\n至此,可以重写RequestMappingHandlerMapping如下：\npublic class HttpSafetyRequestMappingHandlerMapping extends RequestMappingHandlerMapping&#123;    private RequestMappingInfo.BuilderConfiguration config &#x3D; new RequestMappingInfo.BuilderConfiguration();    @Override    protected RequestMappingInfo createRequestMappingInfo(RequestMapping requestMapping,                                                          RequestCondition&lt;?&gt; customCondition) &#123;        &#x2F;&#x2F; 如果Controller的方法上RequestMapping没有指定Method，则只支持GET和POST        RequestMethod[] methods &#x3D; &#123; RequestMethod.GET, RequestMethod.POST &#125;;        if(requestMapping.method().length !&#x3D; 0)&#123;            methods &#x3D; requestMapping.method();        &#125;        return RequestMappingInfo                .paths(resolveEmbeddedValuesInPatterns(requestMapping.path()))                .methods(methods)                .params(requestMapping.params())                .headers(requestMapping.headers())                .consumes(requestMapping.consumes())                .produces(requestMapping.produces())                .mappingName(requestMapping.name())                .customCondition(customCondition)                .options(config)                .build();    &#125;    @Override    protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123;        RequestMappingInfo info &#x3D; createRequestMappingInfo(method);        if (info !&#x3D; null) &#123;            RequestMappingInfo typeInfo &#x3D; createRequestMappingInfo(handlerType);            if (typeInfo !&#x3D; null) &#123;                info &#x3D; typeInfo.combine(info);            &#125;        &#125;        return info;    &#125;    private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123;        RequestMapping requestMapping &#x3D; AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class);        RequestCondition&lt;?&gt; condition &#x3D; (element instanceof Class ?                getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element));        if(requestMapping &#x3D;&#x3D; null)&#123;            return null;        &#125;        &#x2F;&#x2F; 只需要处理方法上的RequestMapping，Controller类上的不需要处理        if(element instanceof Class)&#123;            return super.createRequestMappingInfo(requestMapping, condition);        &#125; else &#123;            return createRequestMappingInfo(requestMapping, condition);        &#125;    &#125;    @Override    public void afterPropertiesSet() &#123;        this.config &#x3D; new RequestMappingInfo.BuilderConfiguration();        this.config.setUrlPathHelper(getUrlPathHelper());        this.config.setPathMatcher(getPathMatcher());        this.config.setSuffixPatternMatch(useSuffixPatternMatch());        this.config.setTrailingSlashMatch(useTrailingSlashMatch());        this.config.setRegisteredSuffixPatternMatch(useRegisteredSuffixPatternMatch());        this.config.setContentNegotiationManager(getContentNegotiationManager());        super.afterPropertiesSet();    &#125;&#125;\n\n如何替换网关服务采用Spring boot开发，那么我们可以从org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration入手。此类中有一个内部类：EnableWebMvcConfiguration，它继承并重写了createRequestMappingHandlerMapping方法。我们知道，在WebMvcConfigurationSupport类中，RequestMappingHandlerMapping实例的获取是通过其：requestMappingHandlerMapping方法上增加Bean注解来实现的。\n这几个类的关系：\nWebMvcConfigurationSupport^| 继承DelegatingWebMvcConfiguration^| 继承EnableWebMvcConfiguration^      ^ |      | @Import|　WebMvcAutoConfigurationAdapter|　　　　　　　 ^ 静态内部类|             || 静态内部类　　|WebMvcAutoConfiguration\n\n在WebMvcConfigurationSupport的requestMappingHandlerMapping方法中，RequestMappingHanlderMapping是通过调用createRequestMappingHandlerMapping方法来实现的。所以要覆盖RequestMappingHanlderMapping的实现，只需要重写createRequestMappingHandlerMapping即可。而EnableWebMvcConfiguration已经将这个方法重写如下：\n      @Overrideprotected RequestMappingHandlerMapping createRequestMappingHandlerMapping() &#123;\tif (this.mvcRegistrations !&#x3D; null\t\t\t&amp;&amp; this.mvcRegistrations.getRequestMappingHandlerMapping() !&#x3D; null) &#123;\t\treturn this.mvcRegistrations.getRequestMappingHandlerMapping();\t&#125;\treturn super.createRequestMappingHandlerMapping();&#125;\n从上面的代码可以看出，EnableWebMvcConfiguration已经提供了替换RequestMappingHandlerMapping的方式，那就是：WebMvcRegistrations。而WebMvcRegistrations是个接口，并有一个默认的空实现：WebMvcRegistrationsAdapter，只需要覆盖其中的getRequestMappingHandlerMapping方法即可。\n@Componentpublic class SafetyWebMvcRegistrationsAdapter extends WebMvcRegistrationsAdapter&#123;    @Override    public RequestMappingHandlerMapping getRequestMappingHandlerMapping() &#123;        return new HttpSafetyRequestMappingHandlerMapping();    &#125;&#125;\n至此Sping boot中替换RequestMappingHandlerMapping的实现就结束了。\n不过我们另一个服务采用的是Spring mvc,上面的替换就不生效了。因为服务中WebApplicationContext是通过@EnableWebMvc注入的配置。而在这个注解中导入的实际上是DelegatingWebMvcConfiguration。\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125;\n所以把@EnableWebMvc替换成@Import(WebMvcAutoConfiguration.EnableWebMvcConfiguration.class)即可。或者重写DelegatingWebMvcConfiguration，覆盖createRequestMappingHandlerMapping方法也是可以的。\n","categories":["Spring"],"tags":["Spring"]},{"title":"如何获取用户真实IP","url":"http://heqiao2010.github.io/2019/06/14/如何获取用户真实IP/","content":"\n在web开发过程中，我们经常需要获取用户客户端的真实IP。比如我们想知道客户的地理位置分布；比如服务端需要将会话和IP地址绑定，以提高安全性等。但是一般在分布式系统中，为了提高系统的可靠性和性能，都会采用代理来分发用户的请求，导致获取用户真实IP变得有些麻烦。\n\n获取调用方IP的方法直接调用HttpServletRequest中的request.getRemoteAddr()方法，获取的IP地址，是当前服务的上游服务的IP地址，在没有代理的情况下是准确的，不过一般都会有一个或者多个代理，这种方式一般不适用。一般可能用如下几个字段\nX-FORWARDED-FORX-FORWARDED-FOR这个http头是个调试参数，在代理服务器上做相关的配置，能够实现，在经过每一个代理的时候，会往后追加上代理的IP地址；这样通过这个字段就可以知道，这个请求被代理了多少次，每次代理是由那个IP处理的；所以取列表第一个IP就是用户的真实IP地址了。\nnginx支持X-FORWARDED-FOR的配置：\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\nProxy-Client-IP用apache http做代理时一般会加上Proxy-Client-IP请求头\nWL-Proxy-Client-IPweblogic插件加上的头\nHTTP_CLIENT_IP有些代理服务器会加上此请求头。\nX-Real-IP在nginx中可以把上游调用的真实IP加到HTTP请求头中，这个IP从remote_addr变量中获取是从TCP链接中获取的真实IP。\nproxy_set_header X-Real-IP $remote_addr;\n\n某些特殊情况正常我们会按照上面的顺序按照优先级获取真实的IP地址。网上一般都会把X-FORWARDED-FOR这个参数作为第一优先级来处理。但是这个参数实际上是不安全的。X-FORWARDED-FOR这个参数的值是个列表，每次经过代理都是往后追加，而不是覆盖的。所以不能确保IP是可信的。客户端可以先伪造一个IP放到头部，真实IP就会在伪造IP之后了。比如：\n客户端伪造\nX-FORWARDED-FOR：　1.1.1.1\n经过两次代理（192.168.1.2,192.168.1.3）之后：\nX-FORWARDED-FOR：　1.1.1.1,108.10.10.123,192.168.1.2,192.168.1.3\n这样获取到的IP地址是1.1.1.1，而不是真正的108.10.10.123。其实真实IP已经在列表中了，怎么避免获取伪造的IP？\nnginx有个realip模块，可以通过set_real_ip_from命令制定代理服务器的IP,因为代理服务器的IP地址都是已知的，所以可以通过从右至左依次获取第一个不在代理IP列表中的合法IP就是用户真实IP地址了。\nset_real_ip_from  192.168.1.2;set_real_ip_from  192.168.1.3;real_ip_header    X-Forwarded-For;real_ip_recursive on;\n安装realip模块需要重新编译nginx，比较麻烦，也可以直接通过最上层代理（第一层代理）服务器获取用户真实IP，写入http头部，后端服务优先获取此参数即可。比如：第一层代理是nginx,将remote_addr参数写入X-Real-IP，后端优先获取此参数，其他代理不要覆盖此参数即可；由于参数是覆盖写入的，就算客户端伪造一个X-Real-IP参数头，也会被代理服务器复写为真实的IP.\n参考https://www.jianshu.com/p/1e0124de8e02http://nginx.org/en/docs/http/ngx_http_realip_module.html\n","categories":["服务端"],"tags":["服务端"]},{"title":"git技巧之git stash","url":"http://heqiao2010.github.io/2019/06/13/git技巧之gitstash/","content":"功能英文单词：stash的原意是储藏的意思。当我们在开发过程中，代码写了一部分，由于某种原因需要切换到另一个分支上，比如临时需要切换到另一个需求上开发另一个任务，这个时候就我们就需要某种手段临时保存手头上没有完成的任务，在另一个任务做完了之后，再恢复这个没有完成的任务继续开发。这个过程是不是有点类似，操作系统中发生函数调用时，保存现场和恢复现场？\n示例\n创建存储\ngit stash\n运行这个命令之后，会将当前所有的修改存储起来，再次运行git statu,会发现目录恢复成clean的状态了。这个时候就可以切换到其他分支了。\n\n查看存储列表\ngit stash list\n有时候，我们运行了stash多次，通过上面的命令，可以查看每次存储的记录；类似：\n$ git stash liststash@&#123;0&#125;: WIP on master: 049d078 added the index filestash@&#123;1&#125;: WIP on master: c264051 Revert &quot;added file_size&quot;stash@&#123;2&#125;: WIP on master: 21d80a5 added number to log\n\n恢复存储\n\n\ngit stash apply #应用存储git stash pop　 #应用并删除存储git stash drop　＃删除存储\n\n上面的命令默认对最近一次的存储进行操作，如果需要制定那个存储，可以在明后跟上存储的名称，例如：\ngit stash apply stash@&#123;2&#125;\n\n##从储藏中创建分支\ngit stash branch [分支名]\n有时候想要对于暂存的代码新创建一个分支，可以用上面的命令进行；一般这种情况可能是应用存储时发生冲突，或者是想要创建分支进行其他操作。\n参考https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%EF%BC%88Stashing%EF%BC%89\n","categories":["git"],"tags":["git"]},{"title":"Syslog基础","url":"http://heqiao2010.github.io/2019/06/10/Syslog基础/","content":"Syslog基础Syslog是类Unix操作系统中，用于记录系统日志（产生自本地或者远程操作系统）到本地磁盘的一套日志格式以及对应的程序。完整的syslog日志中包含产生日志的程序模块（Facility）、严重性（Severity或 Level）、时间、主机名或IP、进程名、进程ID和正文。\nSyslog日志格式Syslog日志格式比较松散，一般分为PRI，HEADER以及MSG三个部分，例如：\n&lt;30&gt;Oct 9 22:33:20 hlfedora auditd[1787]: The audit daemon is exiting.\n\nPRI部分PRI部分由尖括号包含的一个数字构成，这个数字包含了程序模块（Facility）、严重性（Severity），这个数字是由Facility乘以 8，然后加上Severity得来。也就是说这个数字如果换成2进制的话，低位的3个bit表示Severity，剩下的高位的部分右移3位，就是表示Facility的值。Facility的定义如下：\n|Numerical Code |         Facility|-|-|-|           0   |         kernel messages||           1   |         user-level messages||           2   |         mail system||           3   |         system daemons||           4   |         security/authorization messages (note 1)||           5   |         messages generated internally by syslogd||           6   |         line printer subsystem||           7   |         network news subsystem||           8   |         UUCP subsystem||           9   |         clock daemon (note 2)||          10   |         security/authorization messages (note 1)||          11   |         FTP daemon||          12   |         NTP subsystem||          13   |         log audit (note 1)||          14   |         log alert (note 1)||          15   |         clock daemon (note 2)||          16   |         local use 0  (local0)||          17   |         local use 1  (local1)||          18   |         local use 2  (local2)||          19   |         local use 3  (local3)||          20   |         local use 4  (local4)||          21   |         local use 5  (local5)||          22   |         local use 6  (local6)||          23   |         local use 7  (local7)|\nSeverity的定义：\n|Numerical  Code |      Severity|-|-|-|           0    |   Emergency: system is unusable||           1    |   Alert: action must be taken immediately||           2    |   Critical: critical conditions||           3    |   Error: error conditions||           4    |   Warning: warning conditions||           5    |   Notice: normal but significant condition||           6    |   Informational: informational messages||           7    |   Debug: debug-level messages|\nHEADER部分HEADER部分包括两个字段，时间和主机名（或IP）。时间紧跟在PRI后面，中间没有空格，格式必须是“Mmm dd hh:mm:ss”，不包括年份。“日”的数字如果是1～9，前面会补一个空格（也就是月份后面有两个空格），而“小时”、“分”、“秒”则在前面补“0”。月份取值包括：Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec；时间后边跟一个空格，然后是主机名或者IP地址，主机名不得包括域名部分。\nMSG部分MSG部分又分为两个部分，TAG和Content。其中TAG部分是可选的。在前面的例子中（“&lt;30&gt;Oct 9 22:33:20 hlfedora auditd[1787]: The audit daemon is exiting.”），“auditd[1787]”是TAG部分，包含了进程名称和进程PID。PID可以没有，这个时候中括号也是没有的。进程PID有时甚至不是一个数字，例如“root-1787”，解析程序要做好容错准备。TAG后面用一个冒号隔开Content部分，这部分的内容是应用程序自定义的。\n参考https://www.cnblogs.com/skyofbitbit/p/3674664.html\nhttp://www.ietf.org/rfc/rfc3164.txt\nhttp://www.ietf.org/rfc/rfc3195.txt\n","categories":["syslog"],"tags":["linux"]},{"title":"Swagger","url":"http://heqiao2010.github.io/2019/06/06/Swagger/","content":"Swagger使用说明功能简介Swagger是一套治理API的工具，根据OAS（Open Api Specification）这个描述API的规则，实现API盘点、测试以及归档等功能。目前在wisteria功能中，可以在嵌入很少的侵入代码的情况下实现API的盘点功能——我们可以获取到一个最新的，随时和代码保持同步的API文档。\n使用步骤\n引入工程依赖\n compile “io.springfox:springfox-swagger2:2.9.2”\n\n添加API文档支持\n\n\n在项目中，采用开开源的springfox支持API信息的采集。 \n(1)非Spring MVC项目(可以跳过该步骤)\n(2)Spring MVC项目\n需要在MvcConfig中增加@EnableSwagger2注解，同时注入BeanDocket即可。\n@Configuration\n@EnableSwagger2\n@ComponentScan(basePackages = &quot;com.xxx.frontend&quot;,\n    nameGenerator = FullBeanNameGenerator.class)\n@EnableWebMvc\n@EnableAspectJAutoProxy(proxyTargetClass = true)\npublic class MvcConfig extends WebMvcConfigurerAdapter&#123;\n    @Bean\n    public Docket apiDocket() &#123;\n        return new Docket(DocumentationType.SWAGGER_2)\n                .enable(swaggerStatus)\n                .apiInfo(createDefaultApiInfo())\n                .groupName(appName + &quot;frontend&quot;)\n                .select()\n                .apis(RequestHandlerSelectors.basePackage(&quot;com.xxx&quot;))\n                .paths(PathSelectors.any())\n                .build();\n    &#125;\n    private ApiInfo createDefaultApiInfo()&#123;\n        return new ApiInfoBuilder()\n                .title(appName)\n                .description(appName + &quot; frontend api 文档&quot;)\n                .termsOfServiceUrl(&quot;http://www.xxx.cn&quot;)\n                .build();\n    &#125;\n&#125;\n(3)添加API描述\nSpringfox定义了一系列的注解，用于更好的描述各个API的内容，包括输入输出以及字段类型和限制等。如果不添加这些内容，API的信息也是可以获取到的，只是不是很全面而已。\n描述Controller的注解：\n  @Api describes the whole controller  @ApiOperation is used for description on a methods level  @ApiParam is used for method parameters\n示例：\n@RestController\n@RequestMapping(&quot;/v2/persons/&quot;)\n@Api(description = &quot;Set of endpoints for Creating, Retrieving, Updating and Deleting of Persons.&quot;)\npublic class PersonController &#123;\n    private PersonService personService;\n    @RequestMapping(method = RequestMethod.GET, path = &quot;/&#123;id&#125;&quot;, produces = &quot;application/json&quot;)\n    @ApiOperation(&quot;Returns a specific person by their identifier. 404 if does not exist.&quot;)\n    public Person getPersonById(@ApiParam(&quot;Id of the person to be obtained. Cannot be empty.&quot;)\n                                    @PathVariable int id) &#123;\n        return personService.getPersonById(id);\n    &#125;\n&#125;\n描述Model的注解：\n示例：\n&#123;\n    @ApiModel(description = &quot;Class representing a person tracked by the application.&quot;)\n    public class Person &#123;\n    @ApiModelProperty(notes = &quot;Unique identifier of the person. No two persons can have the same id.&quot;, example = &quot;1&quot;, required = true, position = 0)\n    private int id;\n    @ApiModelProperty(notes = &quot;First name of the person.&quot;, example = &quot;John&quot;, required = true, position = 1)\n    private String firstName;\n    @ApiModelProperty(notes = &quot;Last name of the person.&quot;, example = &quot;Doe&quot;, required = true, position = 2)\n    private String lastName;\n    @ApiModelProperty(notes = &quot;Age of the person. Non-negative integer&quot;, example = &quot;42&quot;, position = 3)\n    private int age;\n\n    // … Constructor, getters, setters, ...\n&#125;\n支持JSR-303\n  @NotNull    不为空  @NotBlank   不为空 不为空字符串  @Size(min = 1, max = 20)  字符串长度范围  @Min(0)       最小值最大值设置  @Max(100)  @Pattern(regexp = “[SOME REGULAR EXPRESSION]”)   正则表达式设置  \n做到上面几步就可以在api文档中看到效果了。类似如下：\n\n或者采用不同的展示模板：\n\nSpringfox原理Springfox生成Api文档的原理是，通过获取Spring上下文中@Controller以及@RequestMapping注解的Bean的信息，然后通过层层解析，最终按照Swagger的标准生成Api文档而得来的。\n从RequestMappingHandlerMapping的一段源码上面看，就能够理解在@Controller和@ResquestMapping注解到一个Bean或其属性上之后，Spring做了什么，是如何用HandlerMapping将Http请求映射到响应的Bean的方法上的，以及是如何采用HandlerAdapter来处理Http请求的。\nRequestMappingHandlerMapping中的两个关键方法：\n/**\n * &#123;@inheritDoc&#125;\n * Expects a handler to have a type-level @&#123;@link Controller&#125; annotation.\n */\n@Override\nprotected boolean isHandler(Class&lt;?&gt; beanType) &#123;\n    return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) ||\n            AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class));\n&#125;\n\nprivate RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123;\n    RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class);\n    RequestCondition&lt;?&gt; condition = (element instanceof Class ?\n            getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element));\n    return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null);\n&#125;\nSpringfox获取Controller Bean信息的类图：\n\n参考：https://www.vojtechruzicka.com/documenting-spring-boot-rest-api-swagger-springfox/\nhttps://www.v2ex.com/t/493395\n","categories":["Swagger"],"tags":["Api管理"]},{"title":"记录一个MySql count细节问题","url":"http://heqiao2010.github.io/2019/01/01/记录一个MySql_count细节问题/","content":"\n\n下面两条SQL查询结果会不一样吗？\n\nselect count(1) from   (select distinct &#96;handler_name&#96;, &#96;retry_info&#96;, &#96;is_disabled&#96; from handler) as alia;select count(distinct &#96;handler_name&#96;, &#96;retry_info&#96;, &#96;is_disabled&#96;) from handler;\n\ncount()语法（1）count(*)—包括所有列，返回表中的记录数，相当于统计表的行数，在统计结果的时候，不会忽略列值为NULL的记录。\n（2）count(1)—忽略所有列，1表示一个固定值，也可以用count(2)、count(3)代替，在统计结果的时候，不会忽略列值为NULL的记录。\n（3）count(列名)—只包括列名指定列，返回指定列的记录数，在统计结果的时候，会忽略列值为NULL的记录（不包括空字符串和0），即列值为NULL的记录不统计在内。\n（4）count(distinct 列名)—只包括列名指定列，返回指定列的不同值的记录数，在统计结果的时候，在统计结果的时候，会忽略列值为NULL的记录（不包括空字符串和0），即列值为NULL的记录不统计在内。\n总结由于count（列名）时，为NULL时，不会统计在内，这个点，踩了个坑，这里记录一下，平时还是需要多注意下细节。\n参考https://blog.csdn.net/wendychiang1991/article/details/70909958/\n","categories":["Mysql"],"tags":["MySql"]},{"title":"PropertyUtilsBean","url":"http://heqiao2010.github.io/2018/08/25/PropertyUtilsBean/","content":" \nbeanutils包beanutils，顾名思义，是java bean的一个工具类，可以帮助我们方便的读取(get)和设置(set)bean属性值、动态定义和访问bean属性；细心的话，会发现其实JDK已经提供了一个java.beans包，同样可以实现以上功能，只不过使用起来比较麻烦，所以诞生了apache commons beanutils；看源码就知道，其实apache commons beanutils就是基于jdk的java.beans包实现的。\nAopCacheUtil之前在工作中，写了一个简单的自定义注解，后来自己凭印象写了个AopCacheUtil（还不完整），便于拦截DAO或者Controller层的方法调用，做缓存处理；当中就用到了PropertyUtilsBean，这个类。在解析Bean属性的时候，挺方便的。\norg.apache.commons.beanutils.PropertyUtilsBean.getProperty(Object, String)\n\n参考https://www.cnblogs.com/chenpi/p/6917499.html\n","categories":["Spring"],"tags":["Java"]},{"title":"如何在jar包中读取配置文件 ","url":"http://heqiao2010.github.io/2018/08/02/如何从jar包中读取配置文件/","content":"\n\n今天开发的时候遇到一个问题——当程序以jar包运行的时候,有个txt配置文件无法获取到,但是本地测试无法复现.后来发现是因为以Jar包形式运行，文件无法访问到，这里记录一下。\n\n1. 如何判断当前进程是否以jar包形式运行的？&#x2F;** * 是否以Jar包运行 *  * @return *&#x2F;public static boolean isRunningInJar() &#123;    try &#123;        String className &#x3D; GenericUtils.class.getName().replace(&#39;.&#39;, &#39;&#x2F;&#39;);        String classJar &#x3D; GenericUtils.class.getResource(&quot;&#x2F;&quot; + className + &quot;.class&quot;).toString();        logger.info(&quot;classJar: &quot; + classJar);        return classJar.startsWith(&quot;jar:&quot;);    &#125; catch (Exception e) &#123;        logger.warn(&quot;get Running status failed.&quot;);        return false;    &#125;&#125;\n\n2.从Jar包中读取文件内容public static String txt2String(String fileName) &#123;    StringBuilder result &#x3D; new StringBuilder();    BufferedReader br &#x3D; null;    try &#123;        Reader r &#x3D; null;        if (isRunningInJar()) &#123;            InputStream in &#x3D; GenericUtils.class.getResourceAsStream(File.separator + fileName);            r &#x3D; new InputStreamReader(in);        &#125; else &#123;            String path &#x3D; GenericUtils.class.getClassLoader().getResource(fileName).getPath();            File file &#x3D; new File(path);            r &#x3D; new FileReader(file);        &#125;        br &#x3D; new BufferedReader(r);&#x2F;&#x2F; 构造一个BufferedReader类来读取文件        String s &#x3D; null;        while ((s &#x3D; br.readLine()) !&#x3D; null) &#123;&#x2F;&#x2F; 使用readLine方法，一次读一行            result.append(System.lineSeparator() + s);        &#125;    &#125; catch (Exception e) &#123;        logger.error(&quot;error when function:getTxtFromFile!&quot;, e);    &#125; finally &#123;        try &#123;            if (br !&#x3D; null) &#123;                br.close();            &#125;        &#125; catch (final IOException ioe) &#123;            &#x2F;&#x2F; ignore        &#125;    &#125;    return result.toString();&#125;","categories":["服务端"],"tags":["Java"]},{"title":"基于Ngxtop的QPS监控","url":"http://heqiao2010.github.io/2018/07/14/基于Ngxtop的QPS监控/","content":"\n\n之前参与一个公有云项目的开发，系统入口是公有云平台提供的LB。云平台的LB再将请求转发到后方的多台Nginx，Nginx上再做反向代理到后方的服务器。为了获取系统的QPS，我们在Nginx服务器上写了个定时任务脚本，定期采集并发量，然后汇总。\n\n并发量采集脚本\n先安装ngxtop依次运行：sudo yum -y install epel-releasesudo yum -y install python-pip #安装python-pipsudo yum clean all #清除缓存sudo pip install ngxtop #安装Ngxtop\n\n注意：由于ngxtop是通过监控access.log文件来获取并发量的，因此nginx.conf中的access log一定要打开。\n安装好了之后就能得到当前这台nginx服务器上此时的并发量了。当然也可以通过一些参数对请求做一些过滤比如ngxtop -i &#39;status &gt;= 400&#39; print request status http_referer;我们获取的并发数是整个系统的，可以不过滤。\nrunning for 10 seconds, 1035 records processed: 102.47 req&#x2F;secSummary:|   count |   avg_bytes_sent |   2xx |   3xx |   4xx |   5xx ||---------+------------------+-------+-------+-------+-------||    1035 |         4793.348 |   611 |   414 |    10 |     0 |Detailed:| request_path                                            |   count |   avg_bytes_sent |   2xx |   3xx |   4xx |   5xx ||---------------------------------------------------------+---------+------------------+-------+-------+-------+-------|| &#x2F;portal&#x2F;protocol                                        |     351 |            4.427 |    14 |   337 |     0 |     0 || &#x2F;portal&#x2F;protocol&#x2F;onlines                                |\t142 |           29.585 |   142 |     0 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;38&#x2F;1A&#x2F;wKgBjVr-enmAUwbrAAA4icErDmQ64.html |      93 |         7019.968 |    93 |     0 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;20&#x2F;55&#x2F;wKgBK1rX-yGAGUzxAAA2uqGptGw07.html |\t 54 |         4009.000 |    54 |     0 |     0 |     0 || &#x2F;portal&#x2F;getBindStatus                                   |\t 48 |           92.000 |    48 |     0 |     0 |     0 || &#x2F;portal&#x2F;portalError.jsp                                 |\t 44 |         6481.818 |    44 |     0 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;3A&#x2F;C2&#x2F;wKgBjVsHZ2yADQyKAAA2BaQs3gQ79.html |\t 42 |        12323.667 |    41 |     1 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;39&#x2F;D5&#x2F;wKgBjVsDzz-AEZ_BAAA3KhsbE4Q76.html |\t 24 |         8877.833 |    23 |     1 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;3A&#x2F;C2&#x2F;wKgBjVsHZpKAcXlwAAA3pIzc9NQ54.html |\t 14 |         4051.000 |    14 |     0 |     0 |     0 || &#x2F;fs&#x2F;group1&#x2F;M00&#x2F;3A&#x2F;C2&#x2F;wKgBjVsHZ4mAemZDAAA2Ifroljg77.html |\t 12 |         9739.083 |    12 |     0 |     0 |     0 |\n\n由于ngxtop命令，需要运行一段时间，才能计算出QPS值，因此我们不能获取这个命令的实时输出，而是需要延时后，取结果。通过如下的shell函数可以做到，延时输出。\ntimeout() &#123;time&#x3D;$1# start the command in a subshell to avoid problem with pipes# (spawn accepts one command)command&#x3D;&quot;&#x2F;bin&#x2F;sh -c \\&quot;$2\\&quot;&quot;expect -c &quot;set echo \\&quot;-noecho\\&quot;; set timeout $time; spawn -noecho $command; expect timeout &#123; exit 1 &#125; eof &#123; exit 0 &#125;&quot;if [ $?  &#x3D; 1 ] ;  thenecho  &quot;Timeout after $&#123;time&#125; seconds&quot;fi&#125;timeout 5s &#x2F;usr&#x2F;bin&#x2F;ngxtop &gt;  $work_dir&#x2F;out.txt   #运行ngxtop命令5s，然后将输出重定向到text文件中。\n剩下的工作就是将qps值从命令中截取出来即可：\nreq_per_sec&#x3D;&#96;&#x2F;usr&#x2F;bin&#x2F;cat $work_dir&#x2F;out.txt|grep records |&#x2F;usr&#x2F;bin&#x2F;awk -F &#39;sec&#39; &#39;&#123;print $1&#125;&#39;|grep -oP -m 1 &quot;record.+&quot;|&#x2F;usr&#x2F;bin&#x2F;awk -F &#39;req&#39; &#39;&#123;print $1&#125;&#39;|&#x2F;usr&#x2F;bin&#x2F;awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;&#96;\n\n\n保证采集脚本在数台nginx服务器上并发执行如何保证采集脚本在多台nginx上几乎同时执行呢——用python-fab实现。\n# -*- coding: utf-8 -*-# !&#x2F;usr&#x2F;bin&#x2F;pythonimport osimport paramikoimport root_pathfrom fabric.api import *from fabric.context_managers import settingsfrom fabric.contrib.files import existsfrom fabric.decorators import hostsfrom utillib import CommonUtilfrom utillib import MySqlUtilfrom ngxtop import NgxtopDaoparamiko.util.log_to_file(&quot;filename.log&quot;)logger &#x3D; CommonUtil.getLogger(__name__)env.user &#x3D; &#39;root&#39;env.key_filename &#x3D; &#39;&#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub&#39;env.hosts&#x3D;CommonUtil.get_value_list(&#39;ngxtop&#39;) # 取nginx机器列表@task@parallel # 保证并发执行def collect_result():    if not exists(&#39;&#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop_statistics&#x2F;concurrent_statistics.sh&#39;):        run(&#39;mkdir -p &#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop_statistics&#39;)        put(&#39;&#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop&#x2F;concurrent_statistics.sh&#39;,&#39;&#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop_statistics&#39;) # 拷贝脚本    result&#x3D;run(&#39;sh &#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop_statistics&#x2F;concurrent_statistics.sh&#39;) # 执行脚本    #logger.info(result)    return result@task@hosts(CommonUtil.get_value_list(&#39;ngxtop&#39;))def delete_script():    run(&#39;rm -rf &#x2F;home&#x2F;azureuser&#x2F;auth-webserver&#x2F;ngxtop_statistics&#x2F;concurrent_statistics.sh&#39;)@task@runs_once # 入库保证只执行一次def save_to_database():    collected_output &#x3D; execute(collect_result)    create_time&#x3D;None    wrong_data_type&#x3D;False    create_time&#x3D;CommonUtil.get_local_time()    insert_table_name &#x3D; &#39;tbl_uam_ngxtop&#39;    for host, info in collected_output.iteritems():        logger.info(&quot;On host &#123;0&#125; last user was &#123;1&#125;&quot;.format(host, info))        data&#x3D;info.split(&#39; &#39;)        ngx_data&#x3D;&#123;&#125;        ngx_data[&#39;create_time&#39;] &#x3D; create_time        if(len(data) &#x3D;&#x3D; 2 ):            # 有些时候，取出的qps值中间可能会缺失一位，这里补5.            ngx_data[&#39;request_per_second&#39;] &#x3D; str(data[0]) + &#39;5&#39; + str(data[1])        else:            ngx_data[&#39;request_per_second&#39;] &#x3D; str(info)        ngx_data[&#39;ip&#39;] &#x3D; str(host)        NgxtopDao.save(insert_table_name,ngx_data)    logger.info(ngx_data)if __name__ &#x3D;&#x3D; &#39;__main__&#39;:    os.system(&#39;fab -f NgxtopCollector.py save_to_database&#39;)\n那么这个python脚本，通过crontab每5min触发一次，就能得到相应的qps数据了。\n数据展示用E-charts做了个表格，这样几个系统的qps值就可以采集到了。其实通过这个可以做一个简单的告警，比如当qps值到达4000时，发送一个告警邮件，或者告警微信消息。\n\n感谢YXS编码实现。\n","categories":["nginx"],"tags":["服务端"]},{"title":"异步线程池优化","url":"http://heqiao2010.github.io/2018/06/22/步线程池优化/","content":"\n\n目前在公司做的一个无线Wi-Fi认证系统，采用公有云模式，24小时不间断服务，而且在上班时间会有业务并发的高峰，目前高峰值能到4000多的qps，在这个领域来说，还是比较高的。在这种场景下需要将一些操作异步执行，以提高页面的响应速度，比如某些情况下将大对象入库，可以采用异步线程去处理，这样在入库没有完成时，请求就可以返回（前提是入库失败，不需要通知给客户端）。那么如何创建异步线程，去执行这种异步操作，在保证效率的同时，还不能被高并发冲垮呢？\n\n异步操作的几种实现方式直接创建一个新线程继承或者实现Runnable接口都可以创建一个异步子线程。\npublic class TestThread1 extends Thread&#123;      private boolean flag &#x3D; true;            public static void main( String args[])      &#123;          TestThread1 t &#x3D; new TestThread1();          t.start();          for( int i&#x3D;0; i&lt;100; i++)          &#123;              try &#123;                  Thread.sleep(1000);              &#125; catch (InterruptedException e) &#123;                  e.printStackTrace();              &#125;              System.out.println(&quot;I&#39;m MainThread.&quot;);          &#125;          t.endSubThread();          System.out.println(&quot;MainThread Stoped.&quot;);      &#125;            public void run()      &#123;          while( this.flag )          &#123;              try &#123;                  Thread.sleep(1000);              &#125; catch (InterruptedException e) &#123;                  e.printStackTrace();              &#125;              System.out.println(&quot;----I&#39;m SubThread.&quot;);          &#125;          System.out.println(&quot;----SubThread Stoped.&quot;);      &#125;            public void endSubThread()      &#123;          this.flag &#x3D; false;      &#125;  &#125;  \n\n直接创建子线程可能会导致高并发请求时，创建线程耗费额外的时间，拖慢响应速度，也可能导致创建的线程数过多导致OOM，并且这种线程是一次性的，不能重用；这种方式，我们一开始就没有采用。\n采用固定大小的线程池线程池大小固定，避免请过多线程出现OOM的问题；而且线程可重用，以提升效率。如果并发数超过线程池大小，则任务会缓存到一个队列中。\npackage com.heqiao2010;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ThreadFactory;import java.util.concurrent.atomic.AtomicInteger;&#x2F;** * Created by h12111 on 2018&#x2F;6&#x2F;23. *&#x2F;public class FixedThreadPool &#123;    &#x2F;**     * 当前线程池中线程数量     *&#x2F;    private AtomicInteger currentThreadNum &#x3D; new AtomicInteger(0);    &#x2F;**     * 线程池大小     *&#x2F;    private static final Integer POOLSIZE &#x3D; 8;    private volatile ExecutorService executor &#x3D; null;    public FixedThreadPool()&#123;        this(POOLSIZE);    &#125;    public FixedThreadPool(Integer poolSize)&#123;        this.executor &#x3D; Executors.newFixedThreadPool(poolSize, new ThreadFactory()&#123;            @Override            public Thread newThread(Runnable r) &#123;                Thread thread &#x3D; new Thread(r);                thread.setName(&quot;FixedThreadPool&quot; + currentThreadNum.incrementAndGet());                thread.setDaemon(true);                System.out.println(currentThreadNum.get() + &quot; thread was created.&quot;);                return thread;            &#125;        &#125;);    &#125;    public void execute(Runnable task)&#123;        this.executor.submit(task);    &#125;&#125;\n测试：\nprivate static AtomicInteger sum &#x3D; new AtomicInteger(1000);public static void main(String args[])&#123;    FixedThreadPool threadPool &#x3D; new FixedThreadPool(100); for(int i&#x3D;0; i&lt;111; i++)        threadPool.execute(() -&gt;&#123;            while(sum.get() &gt; 0)&#123;                System.out.println(Thread.currentThread().getName() + &quot;: TestSum is &quot; + sum.get()); try&#123;                    Thread.sleep(1000);  &#125; catch (InterruptedException e)&#123;                    e.printStackTrace();  &#125;                sum.decrementAndGet();  &#125;        &#125;);  &#x2F;&#x2F; 保证主线程不退出  while(sum.get() &gt; 0)&#123;        System.out.println(&quot;Not finish Yet!&quot;); try&#123;            Thread.sleep(1000);  &#125; catch (InterruptedException e)&#123;            e.printStackTrace();  &#125;    &#125;&#125;\n部分输出如下，当一次性提交111个任务时，只创建了100个线程。\n97 thread was created.FixedThreadPool96: TestSum is 100098 thread was created.FixedThreadPool97: TestSum is 100099 thread was created.FixedThreadPool98: TestSum is 1000100 thread was created.FixedThreadPool99: TestSum is 1000Not finish Yet!FixedThreadPool100: TestSum is 1000FixedThreadPool2: TestSum is 997\n\n线程池优化——采用丢弃策略的线程池查看Executors.newFixedThreadPool的源码会发现，ThreadPoolExecutor的构造参数中传入了一个阻塞式任务队列，而这个队列居然是没有限制大小的。因此，当高并发时，过多的任务不会使系统创建过多的线程，但是都会堆积在队列中，这样同样可能会导致OOM。实际上，采用上面的实现方式，我们用Jmeter做压力测试的时候，就出现溢出了，服务挂了，且不能自愈，于是做了下面的优化。\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123;    return new ThreadPoolExecutor(nThreads, nThreads,  0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), &#x2F;&#x2F;这个队列的最大长度可以是：Integer.MAX_VALUE  threadFactory);&#125;\n改进如下，对于在阻塞队列满了之后的任务，可以采取丢弃处理的策略，保证服务本身的安全。\npackage com.heqiao2010;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicInteger;&#x2F;** * 一个可以丢弃任务的线程池 * Created by heqiao on 2018&#x2F;6&#x2F;22. *&#x2F;public class DiscardableThreadPool &#123;    &#x2F;**     * 当前线程池中线程数量     *&#x2F;    private AtomicInteger currentThreadNum &#x3D; new AtomicInteger(0);    private volatile ExecutorService executor &#x3D; null;    &#x2F;**     * 任务丢弃策略&lt;&#x2F;&gt;     *&#x2F;    public static class DiscardPolicy implements RejectedExecutionHandler&#123;        public DiscardPolicy()&#123;        &#125;        &#x2F;**         * 只是简单的打印了个日志         * @param r         * @param executor         *&#x2F;        @Override        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123;            System.out.println(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + executor.toString());        &#125;    &#125;    public static class Builder &#123;        &#x2F;**         * 线程名前缀         *&#x2F;        private String threadNamePrefix &#x3D; &quot;DiscardableThreadPool&quot;;        &#x2F;**         * 线程池中最小线程数         *&#x2F;        private Integer corePoolSize &#x3D; 16;        &#x2F;**         * 最大线程数         *&#x2F;        private Integer maximumPoolSize &#x3D; 128;        &#x2F;**         * 线程超时回收时间         *&#x2F;        private Long keepAliveTime &#x3D; 5L;        &#x2F;**         * 线程超时回收时间单位         *&#x2F;        private TimeUnit timeUnit &#x3D; TimeUnit.MINUTES;        &#x2F;**         * 任务队列大小         *&#x2F;        private Integer queueCapacity &#x3D; 500;        &#x2F;**         * 丢弃策略         *&#x2F;        private RejectedExecutionHandler handler &#x3D; new DiscardPolicy();        public Builder namePrefix(String prefix)&#123;            this.threadNamePrefix &#x3D; prefix;            return this;        &#125;        public Builder minPoolSize(int minPoolSize)&#123;            this.corePoolSize &#x3D; minPoolSize;            return this;        &#125;        public Builder maxPoolSize(int maxPoolSize)&#123;            this.maximumPoolSize &#x3D; maxPoolSize;            return this;        &#125;        public Builder keepAlive(long keepAliveTime, TimeUnit unit)&#123;            this.keepAliveTime &#x3D; keepAliveTime;            this.timeUnit &#x3D; unit;            return this;        &#125;        public Builder queueCapacity(int capacity)&#123;            this.queueCapacity &#x3D; capacity;            return this;        &#125;        public Builder rejectedHanlder(RejectedExecutionHandler handler)&#123;            this.handler &#x3D; handler;            return this;        &#125;        public DiscardableThreadPool build()&#123;            return new DiscardableThreadPool(this);        &#125;    &#125;    &#x2F;**     * 构造子     * @param builder     *&#x2F;    private DiscardableThreadPool(Builder builder)&#123;        if(null &#x3D;&#x3D; executor)&#123;            &#x2F;&#x2F; 线程工厂            ThreadFactory threadFactory &#x3D; new ThreadFactory() &#123;                @Override                public Thread newThread(Runnable r) &#123;                    Thread thread &#x3D; new Thread(r);                    thread.setName(builder.threadNamePrefix + currentThreadNum.incrementAndGet());                    thread.setDaemon(true);                    System.out.println(currentThreadNum.get() + &quot; thread was created.&quot;);                    return thread;                &#125;            &#125;;            &#x2F;&#x2F; 任务队列            BlockingQueue&lt;Runnable&gt; workQueue &#x3D; new LinkedBlockingDeque&lt;Runnable&gt;(builder.queueCapacity);            &#x2F;&#x2F; 初始化            executor &#x3D; new ThreadPoolExecutor(builder.corePoolSize, builder.maximumPoolSize, builder.keepAliveTime, builder.timeUnit,                    workQueue, threadFactory, builder.handler);        &#125;    &#125;    &#x2F;**     * 执行一个异步任务     * @param task     *&#x2F;    public void execute(Runnable task)&#123;        executor.submit(task);    &#125;    @Override    public String toString() &#123;        return &quot;DiscardableThreadPool&#123;&quot; +                &quot;executor&#x3D;&quot; + executor +                &#39;&#125;&#39;;    &#125;    public boolean isShutDown()&#123;        return executor.isShutdown();    &#125;    public boolean isTeminated()&#123;        return executor.isTerminated();    &#125;&#125;\n\n测试代码：\npackage com.heqiao2010;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;&#x2F;** * 测试！ *&#x2F;public class Main &#123;    private static AtomicInteger sum &#x3D; new AtomicInteger(1000);    public static void main(String[] args) &#123;         &#x2F;&#x2F;最多100个线程，队列大小是10个，理论上最大并发支持到110        DiscardableThreadPool threadPool &#x3D;                new DiscardableThreadPool.Builder().minPoolSize(8)                    .maxPoolSize(100).keepAlive(1, TimeUnit.MINUTES)                    .namePrefix(&quot;Test&quot;).queueCapacity(10)                        .build();          &#x2F;&#x2F;一次性提交111个任务        for(int i&#x3D;0; i&lt;111; i++)        threadPool.execute(() -&gt;&#123;            while(sum.get() &gt; 0)&#123;                System.out.println(Thread.currentThread().getName() + &quot;: TestSum is &quot; + sum.get());                try&#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e)&#123;                    e.printStackTrace();                &#125;                sum.decrementAndGet();            &#125;        &#125;);        &#x2F;&#x2F; 保证主线程不退出        while(sum.get() &gt; 0)&#123;            System.out.println(&quot;Not finish Yet!&quot;);            try&#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e)&#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n部分输出如下，可见在线程池满了，而且队列也满了的情况下，任务就会被丢弃掉了。\nTest98: TestSum is 1000100 thread was created.Test99: TestSum is 1000Test77: TestSum is 1000Test68: TestSum is 1000Test72: TestSum is 1000Test76: TestSum is 1000Test80: TestSum is 1000Test84: TestSum is 1000Task java.util.concurrent.FutureTask@1e80bfe8 rejected from java.util.concurrent.ThreadPoolExecutor@66a29884[Running, pool size &#x3D; 100, active threads &#x3D; 100, queued tasks &#x3D; 10, completed tasks &#x3D; 0]Not finish Yet!Test92: TestSum is 1000Test88: TestSum is 1000Test81: TestSum is 1000Test100: TestSum is 1000\n\n","categories":["服务端"],"tags":["Java"]},{"title":"Java垃圾回收","url":"http://heqiao2010.github.io/2018/06/18/Java垃圾回收/","content":"\n\n在目前我参与的实际项目开发中，启动Java进程时，并没有设置额外的虚拟机参数。因为公司通过k8s集群给我们自己的业务微服务打了标签，基本上时独享整个机器的内存，所以没有增加相关的JVM参数，对这块了解也不多。在上一家公司工作的时候，测试内存溢出用的是Jprofile，运行一段时间之后，手动触发GC，看内存是否增长。\n\nJava虚拟机内存分区Java虚拟机主要分为以下五个区: \n一、方法区： \n1. 有时候也成为永久代，在该区内很少发生垃圾回收，但是并不代表不发生GC，在这里进行的GC主要是对方法区里的常量池和对类型的卸载2. 方法区主要用来存储已被虚拟机加载的类的信息、常量、静态变量和即时编译器编译后的代码等数据。3. 该区域是被线程共享的。4. 方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用。该常量池具有动态性，也就是说常量并不一定是编译时确定，运行时生成的常量也会存在这个常量池中。\n二、堆 \njava堆是所有线程所共享的一块内存，在虚拟机启动时创建，几乎所有的对象实例都在这里创建，因此该区域经常发生垃圾回收操作。\n三、虚拟机栈: \n1. 虚拟机栈也就是我们平常所称的栈内存,它为java方法服务，每个方法在执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接和方法出口等信息。2. 虚拟机栈是线程私有的，它的生命周期与线程相同。3. 局部变量表里存储的是基本数据类型、returnAddress类型（指向一条字节码指令的地址）和对象引用，这个对象引用有可能是指向对象起始地址的一个指针，也有可能是代表对象的句柄或者与对象相关联的位置。局部变量所需的内存空间在编译器间确定4.操作数栈的作用主要用来存储运算结果以及运算的操作数，它不同于局部变量表通过索引来访问，而是压栈和出栈的方式5.每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接.动态链接就是将常量池中的符号引用在运行期转化为直接引用。\n四、本地方法区 \n本地方法区和虚拟机栈类似，只不过本地方法栈为Native方法（对非java语言调用的接口）服务。\n五、程序计数器 \n内存空间小，字节码解释器工作时通过改变这个计数值可以选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理和线程恢复等功能都需要依赖这个计数器完成。该内存区域是唯一一个java虚拟机规范没有规定任何OOM情况的区域。\n垃圾回收的特点程序计数器、虚拟机栈、本地方法栈这3个区域是随线程而生而灭的，内存分配和回收都具备确定性，而Java堆和方法区则不一样，各线程共享，在运行时内存的分配与回收都是动态的，垃圾收集器所关注的是这部分内存。\n了解垃圾回收机制的必要性虽然垃圾回收机制已经比较成熟和稳定，但是当遇到如下情况时，就必须关注垃圾回收机制本身了。\n\n当需要排查各种内存溢出、内存泄漏问题时；\n当垃圾收集成为系统达到更高并发量的瓶颈时；\n\n垃圾回收算法做的事情\n回收什么\n什么时候回收\n怎么回收\n\n1. 回收什么\n引用计数算法（Recference Counting）\n\n思路: 给对象添加一个引用计数器，每当有一个地方引用它，计数器加1；当引用失效，计数器值减1；任何时刻计数器值为0，则认为对象是不再被使用的；优点: 实现简单，判定高效，可以很好解决大部分场景的问题;缺点: 1)很难解决对象之间相互循环引用的问题 2)开销较大，频繁且大量的引用变化，带来大量的额外运算;\n参考1：https://blog.csdn.net/tjiyu/article/details/53982412\n","categories":["服务端"],"tags":["Java"]},{"title":"TCP链接数优化记录","url":"http://heqiao2010.github.io/2018/06/15/TCP链接数优化记录/","content":" \n\n之前在开发无线wifi认证系统的时候，遇到一次性能问题，表现就是前端3台nginx返回大量502和504，所有接口返回慢，包括html，css以及js等资源文件的响应也很慢。在后端服务器上，用netstat查看发现有大量数据阻塞在接收队列，服务器处理不过来，同时TCP链接数很多，不过后端服务器的CPU以及内存正常，所以之前怀疑是TCP链接数过多导致的，所以后续采取了一些方法来，减少后端服务器和前端nginx之间的链接数。\n\n查看TCP链接\n查看TCP链接总数总体来说，TCP连接数偏多\n\n[root@portal-nginx2 ~]# netstat -an | grep ES| wc -l6326\n\n\n查看TCP链接队列情况如果接受队列阻塞了，说明后端服务处理请求太慢了，有性能问题；如果发送队列包很多，说明接收端有问题，或者虚机网络问题。\n\nActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State...tcp        0  10369 192.168.1.10:10080      100.125.64.100:16916    ESTABLISHEDtcp        0  13169 192.168.1.10:10080      100.125.64.97:16809     ESTABLISHEDtcp        0  13568 192.168.1.10:10080      100.125.64.96:17071     ESTABLISHEDtcp        0  13595 192.168.1.10:10080      100.125.64.97:17074     ESTABLISHEDtcp        0  13596 192.168.1.10:10080      100.125.64.98:17070     ESTABLISHEDtcp        0  14600 192.168.1.10:10080      100.125.64.109:23059    ESTABLISHEDtcp        0  14851 192.168.1.10:10080      100.125.64.103:23019    ESTABLISHEDtcp        0  16157 192.168.1.10:10080      100.125.64.82:16914     ESTABLISHEDtcp        0  17680 192.168.1.10:10443      100.125.64.104:18713    ESTABLISHEDtcp        0  18653 192.168.1.10:10080      100.125.64.126:56441    ESTABLISHEDtcp        0  19766 192.168.1.10:10443      100.125.64.114:18725    ESTABLISHEDtcp        0  32120 192.168.1.10:10080      100.125.64.117:23044    ESTABLISHEDtcp        0  45716 192.168.1.10:10443      100.125.64.113:18725    ESTABLISHEDtcp        0  47955 192.168.1.10:10080      100.125.64.116:23033    ESTABLISHEDtcp        0  54595 192.168.1.10:10080      100.125.64.90:16961     ESTABLISHEDtcp        0  54600 192.168.1.10:10080      100.125.64.85:16961     ESTABLISHEDtcp        0  62454 192.168.1.10:10080      100.125.64.149:46132    ESTABLISHEDtcp        0  63689 192.168.1.10:10080      100.125.64.127:56506    ESTABLISHED\n\n\n\n系统参数设置这几个系统参数，印象最深的是net.ipv4.tcp_fin_timeout,系统默认值是60，表示链接断开后，链接保持fin_wait的时间（我记得阿里的java开发规范里有提到这个）。\n[root@XXX ~]# cat &#x2F;etc&#x2F;sysctl.conf# sysctl settings are defined through files in# &#x2F;usr&#x2F;lib&#x2F;sysctl.d&#x2F;, &#x2F;run&#x2F;sysctl.d&#x2F;, and &#x2F;etc&#x2F;sysctl.d&#x2F;.## Vendors settings live in &#x2F;usr&#x2F;lib&#x2F;sysctl.d&#x2F;.# To override a whole file, create a new file with the same in# &#x2F;etc&#x2F;sysctl.d&#x2F; and put new settings there. To override# only specific settings, add a file with a lexically later# name in &#x2F;etc&#x2F;sysctl.d&#x2F; and put new settings there.## For more information, see sysctl.conf(5) and sysctl.d(5).net.ipv4.icmp_echo_ignore_broadcasts &#x3D; 1 #避免放大攻击net.ipv4.tcp_max_syn_backlog&#x3D;8192  #表示SYN队列的长度，默认为1024net.core.netdev_max_backlog&#x3D;30000   #进入包的最大设备队列.默认是1000net.core.somaxconn&#x3D;8192 #挂起请求的最大数量.默认是128.net.ipv4.ip_local_port_range &#x3D; 3000     65000  #端口范围，可用端口数net.ipv4.tcp_fin_timeout &#x3D; 30net.ipv4.tcp_max_tw_buckets&#x3D;5000 #表示系统同时保持TIME_WAIT套接字的最大数量\n\n修改完后，sysctl -p生效。\n反向代理设置nginx.conf中的upstream配置增加keepalive参数，keepalive后的参数是以秒为单位的时间。\nupstream portal &#123;            server 192.168.1.128:7878;            server 192.168.1.60:7878;            server 192.168.1.82:7878;            server 192.168.1.69:7878;            server 192.168.1.253:7878;            server 192.168.1.160:7878;            server 192.168.1.33:7878;            keepalive 500;    &#125;\n\n这里谈到keepalive就想到了TCP的keepalive了，TCP的keepalive机制实际上是在没有数据传输的一个保活机制。TCP在3次握手之后，就可以开始传输数据了，但是当没有数据可传输的时候，为了知道对端是否还保持这个链接，TCP协议会定期发送一个数据为空的探测报文，看看对端是否会响应这个报文，如果不响应，则说明这个链接已经丢失了。TCP的keepalive可以设置TCP协议在没有数据传输后多久开始发送探测报文，以及发送探测报文重试次数等等。\n实际上上面nginx.conf中，这个keepalive不是配置TCP探测报文的（nginx.conf中真正TCP探测报文的配置是通过so_keepalive控制的），这个keepalive的官方解释如下：\n\nThe connections parameter sets the maximum number of idle keepalive connections to upstream servers connections（设置到upstream服务器的空闲keepalive连接的最大数量）\nWhen this number is exceeded, the least recently used connections are closed. （当这个数量被突破时，最近使用最少的连接将被关闭）\nIt should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open.（特别提醒：keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量）\n\nhttp的传输层协议是TCP，一个http请求是通过TCP传输的数据，当一个http请求发出，然后得到响应之后，TCP链接可能会关闭，下一次发起http请求时，再重新创建TCP链接，这个过程，必然会有TCP多次创建的过程，而创建过程会消耗额外资源。如果能够在一段时间内复用之前已经创建的TCP链接，则可以提升效率。这个超时时间可以通过nginx.conf中http部分的keepalive_timeout来控制。\nkeepalive_timeout timeout [header_timeout];\n\n参考1：https://www.cnblogs.com/xiaoleiel/p/8308514.html参考2：https://blog.csdn.net/dream_flying_bj/article/details/54709549\n","categories":["服务端"],"tags":["服务端"]},{"title":"Shell 实现的几个Http交互的方法","url":"http://heqiao2010.github.io/2018/06/14/Shell实现的几个Http交互的方法/","content":" \n\n由于测试需求，需要测试一些http接口是否正常，作为后端开发可以用脚本语言来实现比如python,shell之类的，这里分享一下，用shell如何实现。\n\n\nURLencode方法既然是http接口，必定会用到urlencode来将参数放入URL中。\nurl_encode()&#123;   echo  &quot;$1&quot; | tr -d  &#39;\\n&#39; | xxd -plain | sed &#39;s&#x2F;\\(..\\)&#x2F;%\\1&#x2F;g&#39; | tr -d  &#39;\\n&#39;    return  0 &#125;\n\nURLdecode方法\nurl_decode()&#123;        printf $(echo -n $t | sed &#39;s&#x2F;\\\\&#x2F;\\\\\\\\&#x2F;g;s&#x2F;\\(%\\)\\([0-9a-fA-F][0-9a-fA-F]\\)&#x2F;\\\\x\\2&#x2F;g&#39;)        return 0&#125;\n\n解析JSON数据，从JSON对象中获取某个属性\nparse_json()&#123;    json&#x3D;&#96;echo $1 | sed &#39;s&#x2F;\\&quot;&#x2F;&#x2F;g&#39;&#96;; #remove quotation mark    echo $json | sed &#39;s&#x2F;.*&#39;$2&#39;:\\([^,&#125;]*\\).*&#x2F;\\1&#x2F;&#39;    return 0&#125;\n\n解析URL参数，从URL中获取某个参数的值\nparse_uri_paras()&#123;    echo $1 | sed &#39;s&#x2F;.*&#39;$2&#39;&#x3D;\\([[:alnum:]]*\\).*&#x2F;\\1&#x2F;&#39;    return 0&#125;\n\n获取重定向地址\nrequest_redirect_url()&#123;    echo &#96;curl -i &quot;$1&quot; 2&gt;&#x2F;dev&#x2F;null  | sed -n &#39;s&#x2F;^Location:&#x2F;&#x2F;p&#39;&#96;    return 0&#125;\n\n发送简单的GET请求\nhttp_get()&#123;    get_data&#x3D;&#96;curl -X GET &quot;$1&quot; 2&gt;&#x2F;dev&#x2F;null&#96;    if [ &quot;$get_data&quot; &#x3D;  &quot;&quot; ]; then #出错了            echo &quot;出错了，试试：curl -X GET \\&quot;$1\\&quot;&quot;            exit 1    else         echo $get_data        return 0    fi&#125;\n\n发送简单的POST请求\nhttp_post()&#123;    post_data&#x3D;&#96;curl -X POST -d &quot;$1&quot; $2 2&gt;&#x2F;dev&#x2F;null&#96;    if [ &quot;$post_data&quot; &#x3D;  &quot;&quot; ]; then #出错了                echo &quot;出错了，试试：curl -X POST \\&quot;$1\\&quot; \\&quot;$2\\&quot;&quot;                exit 1        else                echo $post_data                return 0        fi&#125;\n\n","categories":["服务端"],"tags":["Java"]},{"title":"几道逻辑思维题","url":"http://heqiao2010.github.io/2018/06/14/几道逻辑思维题/","content":"\n\n上个月去一个互联网公司面试，三面的时候面试官出了两道思维逻辑题，挺有意思的，这里记录一下。\n\n1.过河问题\n描述：有一条河，河岸边有一个警察，一个犯人，一个父亲和两个儿子，一个母亲和两个女儿，河边只有一条船，这8个人要过河；\n约束：  1.能划船的只有警察，父亲和母亲；  2.船上同一时刻只能有两个人，包括小孩；  3.犯人会在警察不在身边的时候伤害其他人，父亲会在母亲不在的时候，伤害女儿，母亲会在父亲不在的时候伤害儿子；\n问题：这些人如何过河，才能确保大家都相安无事？\n\n思路：把所有的可能情况，全部列一遍就出来了。\n2.赛马问题\n描述：一共有25匹马，只有5个赛马道，每次赛马只能看出名次，不知道快慢，请问如何比赛才能以最少的次数，选出前3名跑的最快的马？\n\n思路：先每5匹分一组，都赛一次，就是5次；然后找出5个第一名，再赛一次，然后淘汰最差的那两组，取倒数第3名那组的第一名，取倒数第4名那组中的前两名，取最快那组中的第二和第三名，恰好就是5匹，再赛一次，取前两名（最快的吗第6次就知道了）就得到结果了，因此是7次。\n","categories":["面试"],"tags":["面试题"]},{"title":"面试题记录","url":"http://heqiao2010.github.io/2018/06/14/面试题记录/","content":"\n\n今天去某互联网公司面试，从3点一直面试道6点多，面的怎么样倒不清楚，有几道题挺有意思的，这里记录下。\n\n1.区间合并  写一个方法将如下区间合并：  例如输入：  [1,2],[4,6],[5,8],[10,11]  输出：  [1,2],[4,8],[10,11]  思路：先排序，然后尝试将相邻两个区间合并，遍历整个区间即可；  public List&lt;Order&gt; merge(List&lt;Order&gt; list)&#123;  &#x2F;&#x2F;...&#125; \n2.求进行中订单的最大数量  假设订单都有订单ID，开始时间StartTime以及结束时间EndTime（时间单位均是秒），那么如何求某一天24h内，进行中订单的最大数量？  思路：这道题没有想到特别好的思路，直接是用遍历处理的。。。这个可以研究下。。。\n3.判断IP是否在IP黑名单中  IP黑名单是有IP地址区间表示的，比如【192.168.100.1，192.168.101.255】，然后有很多个这样的黑名单BlackList，现在要写一个方法，如何快速的判断一个IP地址，是否在这个黑名单中。  思路：IP地址是字符串，字符串比较太慢，可以将IP地址转化为一个整数，这样就相当于判断整数是否在这些区间中了，所以步骤如下：  1）.转化为整数；  2）.将区间排序；  3）.将区间合并；  4）.用二分法查找有序区间，判断是否在区间内。\n\n更新：突然想到第二题，可以这样优化：  1）排序  2）然后依次从列表中取区间，进行合并；  3）如果两个区间有交集则计数器加一，区间变成交集区间，再继续，直到和下一个区间没有交集为止，这个时候记录一下这个计数器的值，那么这个值就是已处理过区间中，同时派发订单的最大值，把这个当前最大值放入一个集合；  4）接着重新计数，重新合并区间，知道所有的记录都处理完毕；  5）从计数集合中找出最大值即可。\n","categories":["面试"],"tags":["面试题"]},{"title":"Solo博客搭建","url":"http://heqiao2010.github.io/2018/06/12/关于博客搭建/","content":" \n\n用Github Pages可以搭静态博客，可以写点东西，不过不能有人评论，毕竟是静态页面。今天突然想到去年在Godaddy买了个域名一直没有用，今天就索性在搬瓦工买了个linux虚机搭个动态博客试试。\n\n虚机软件安装购买虚机就不用说了，190块/年，买了个最低配的linux虚机，安装了ubuntu12.4系统，动态博客是基于solo搭建的，由于solo是用java开发的，所以先要安装jdk。solo跑起来了之后，发现一个很奇特的现象——80端口不通，但是8080端口是好使的，用netstat查看，没有80端口的TCP链接。latke.properties中的端口不是服务的监听端口，solo服务真正的监听端口是8080，而且没有找到在哪个里面配置的。\nnginx配置为了解决这个问题，直接装了个nginx，做了个反向代理（老套路…）：\nupstream blog &#123;            server xx.xx.xx.xxx:8080;    &#125;server &#123;                listen  80;        server_name heqiao2010.com;                location &#x2F; &#123;                    proxy_pass http:&#x2F;&#x2F;blog&#x2F;;                    proxy_http_version 1.1;                    proxy_set_header Connection &quot;&quot;;                    proxy_ignore_client_abort   on;                    proxy_set_header Host $host:80;                    proxy_set_header X-Real-IP $remote_addr;                    proxy_set_header X-Forwarded-Proto  $scheme;                    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;                    proxy_set_header Via &quot;nginx&quot;;                &#125;        &#125;\n\n域名映射有个没有搞明白的问题是域名映射；在Godaddy上完全看不懂，配置完后，过了一会儿就可以了，估计有缓存。。。\n\n","categories":["杂七杂八"],"tags":["服务端"]},{"title":"CentOs安装Jmeter","url":"http://heqiao2010.github.io/2018/05/13/Centos安装jmeter/","content":"\n前段时间公司生产环境，压力增长了不少，后来出过几次性能问题；为了避免高峰期服务器压力过大，导致服务不可用的情况，领导要求每次合入影响性能的代码之后，都需要做压力测试了。我们用jmeter做压力测试，之前是在实验室环境的window上安装图形化的jmeter进行测试，但是由于实验室带宽限制，流量达不到要求，后来就直接在服务器上安装jmeter基于命令行打流；\n\n#如何在CentOS中安装Jmeter\n\nInstall JRE\n yum install java\n\n下载jmeter\n wget http://mirrors.hust.edu.cn/apache//jmeter/binaries/apache-jmeter-4.0.tgz tar zxf apache-jmeter-4.0.tgz\n\n拷贝到系统目录\n mv apache-jmeter-4.0 /usr/local/\n\n修改profile\n vim /etc/profile\n 然后追加：\n #/usr/local/apache-jmeter-4.0 export JMETER=/usr/local/apache-jmeter-4.0/ export CLASSPATH=$JMETER/lib/ext/ApacheJMeter_core.jar:$JMETER/lib/jorphan.jar:$JMETER/lib/logkit-2.0.jar:$CLASSPATH export PATH=$JMETER/bin/:$PATH\n 然后source生效 source /etc/profile\n\n验证\n\n\n[?]# jmeter -vMay 12, 2018 9:44:30 AM java.util.prefs.FileSystemPreferences$1 run\nINFO: Created user preferences directory._ ____ _ ____ _ _ _____ _ __ __ _____ _____ _____ ____/ \\ | _ \\ / \\ / ___| | | | ____| | | \\/ | ____|_ _| ____| _ \\/ _ \\ | |_) / _ \\| | | |_| | _| _ | | |\\/| | _| | | | _| | |_) |/ ___ \\| __/ ___ \\ |___| _ | |___ | |_| | | | | |___ | | | |___| _ &lt;/_/ \\_\\_| /_/ \\_\\____|_| |_|_____| \\___/|_| |_|_____| |_| |_____|_| \\_\\ 4.0 r1823414Copyright (c) 1999-2018 The Apache Software Foundation\n\n如何基于命令行运行\n jmeter -n -t test1.jmx -l result.log 2&gt;/dev/null\n\n\n","categories":["服务端"],"tags":["服务端"]},{"title":"Java中锁的使用","url":"http://heqiao2010.github.io/2018/05/13/Java中锁简单使用/","content":"\n工作3年多了，写过一点点Java代码，用过sychronized，不过确实没有用过Lock这个东西，今天抽时间看看。\n\n其实Lock是个接口：\npublic interface Lock &#123;\t &#x2F;&#x2F; 获取锁，如果锁被占用，则等待；    void lock();    &#x2F;&#x2F;     void lockInterruptibly() throws InterruptedException;    boolean tryLock();    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;    void unlock();    Condition newCondition();&#125;\n\n","categories":["服务端"],"tags":["Java"]},{"title":"某公司两道面试题","url":"http://heqiao2010.github.io/2018/05/13/某公司两道面试题/","content":"\n今天下午接到某公司笔试的通知，面试官发过来一个链接，打开之后，发现是两道笔试题，看似简单，但是打完之后，面试官直接关了页面，结果可想而知，这里分享一下这两道题，后面想想更好的解决方案。\n\n\n查找整数输入：一个有序数组array，一个整数n输出：如果n在array里，输出n的位置；如果n不在array中输出n可以插入的位置，插入后的数组仍然有序例如：  \n\n*[1,3,5,6], 5 → 2*[1,3,5,6], 2 → 1*[1,3,5,6], 7 → 4*[1,3,5,6], 0 → 0  \n我的答案：\n&#x2F;&#x2F; 默认升序，如果降序需要反过来public int findPosition(int arr[], int n)&#123; int min &#x3D; 0;    int max &#x3D; arr.length - 1;     if(null &#x3D;&#x3D; arr || arr.length &#x3D;&#x3D; 0)&#123;     return -1;     &#125;     if(n &gt; arr[max])&#123;     return max + 1;    &#125;      if(n &#x3D;&#x3D; arr[max])&#123;     return max;     &#125;     if(n &lt;&#x3D; arr[min])&#123;     return min;    &#125;     while(max - min &gt; 1)&#123;     int newIndex &#x3D; (max + min) &#x2F; 2;       if(arr[newIndex] &gt; n)&#123;         &#x2F;&#x2F;取小区间           max &#x3D; newIndex;        &#125; else if(arr[newIndex] &lt; n)&#123;         &#x2F;&#x2F;取大区间           min &#x3D; newIndex;        &#125; else&#123;         &#x2F;&#x2F;相等，找到了           return newIndex;        &#125;    &#125;   if(arr[max] &#x3D;&#x3D; n)&#123;     return max;    &#125; else if(arr[min] &#x3D;&#x3D; n)&#123;     return min;    &#125; else &#123;     &#x2F;&#x2F; 可以插入位置在min后     return min + 1;    &#125;&#125;\n\n\n分析：上面只是做了一个简单的二分查找，有没有更优的解决方案，后面还需要再研究下。\n\n字符串查找输入: 字符串str1， 字符串str2输出: 字符串str2在字符串str1中第一次出现的位置。如果没有返回-1.例如： str1=“www.taobao.com” str2=”taobao” -&gt; 4其它要求：不能使用String类的indexOf方法  \n\n我的答案：  \npublic class Solution &#123;    public int strStr(String str1, String str2) &#123;     if(null &#x3D;&#x3D; str1 || null &#x3D;&#x3D; str2 || str1.length()&lt;str2.length())&#123;         return -1;        &#125;         int i &#x3D; 0; &#x2F;&#x2F; str1 p1        while(i&lt;str1.length())&#123;         int j &#x3D; 0; &#x2F;&#x2F; str2 p2         while( str1.length() &gt;&#x3D; (i + j)              &amp;&amp; str1.charAt(i + j) &#x3D;&#x3D; str2.charAt(j))&#123;                j++;                if(j &#x3D;&#x3D; str2.length())&#123;                 return i;                &#125;            &#125;             i++;        &#125;      return -1;    &#125;&#125;                &#125;&#125;\n\n分析：我的答案只是传统的字符串匹配方式，大学里面学的KMP早已忘记，很尴尬，😅。\n","categories":["面试"],"tags":["面试题"]},{"title":"一个全新的开始","url":"http://heqiao2010.github.io/2018/05/06/newstart/","content":"\n总算搬新家了，自如的房子有点贵。。。\n\n只看下桌子吧\n","categories":["杂七杂八"],"tags":["杂谈"]},{"title":"GitStats不错","url":"http://heqiao2010.github.io/2018/02/15/gitstats/","content":"\n缘起：2017年老板说要搞一个年终总结，写了一个PPT，老板看了，觉得太虚，需要一些数据展示。而基于git原生的一些代码统计显得太单调了，发现网上大神写的gitstats工具不错。\n\n安装\n安装依赖：Git，Python，Gnuplot。\ngit clone git://github.com/hoxu/gitstats.git\n\n\n小插曲：在mac上安装Gnuplot的时候报错：invalid active developer path (/Library/Developer/CommandLineTools)\n解决方法：在终端中执行如下命令：xcode-select --install系统弹出下载xcode相关插件，大概1分钟安装完毕，然后重试OK。\n\n使用gitstats下载下来之后，解压一共有如下几个文件：-rw-r–r–@  1 heqiao  staff   1.0K  1  9  2016 Makefile -rw-r–r–@  1 heqiao  staff    73B  1  9  2016 arrow-down.gif-rw-r–r–@  1 heqiao  staff    71B  1  9  2016 arrow-none.gif-rw-r–r–@  1 heqiao  staff    73B  1  9  2016 arrow-up.gifdrwxr-xr-x@ 10 heqiao  staff   320B  1  9  2016 doc-rwxr-xr-x@  1 heqiao  staff    47K  1  9  2016 gitstats-rw-r–r–@  1 heqiao  staff   1.6K  1  9  2016 gitstats.css-rw-r–r–@  1 heqiao  staff   9.3K  1  9  2016 sortable.js\n其中最重要的就是gitstats，这个文件，实际上是个python脚本，运行：./gitstats [git仓库] [统计文件输出文件夹]得到如下输出：[0.01650] &gt;&gt; gnuplot –versionOutput path: /Users/heqiao/Downloads/hoxu-gitstats-55c5c28/resultGit path: solo/Collecting data…[0.11579] &gt;&gt; git shortlog -s HEAD | wc -l[0.00874] &gt;&gt; git show-ref –tags[0.00897] &gt;&gt; git log “3580b4353004c88c8b8e6283aea1889be149074a” –pretty=format:”%at %aN” -n 1[0.00794] &gt;&gt; git log “0473873adfc4820e1371f112325b8d733aec11f8” –pretty=format:”%at %aN” -n 1[0.00774] &gt;&gt; git log “f302f95132b561b2d906b47c64cb5a2c8f6775f9” –pretty=format:”%at %aN” -n 1[0.00895] &gt;&gt; git log “d78c8dc9e1e9f8bdfa047f2e4435daaf941c0d5a” –pretty=format:”%at %aN” -n 1[0.01002] &gt;&gt; git log “80b05fb7bd09f860a8e79ceee61cf787aa6682ca” –pretty=format:”%at %aN” -n 1[0.00767] &gt;&gt; git log “93f81cd81508f2c8a8fb64b6e4286062c023885e” –pretty=format:”%at %aN” -n 1[0.00758] &gt;&gt; git log “1326eddf83578d992a4f08e45a5ddf3c9dd82431” –pretty=format:”%at %aN” -n 1[0.00756] &gt;&gt; git log “a6356478a743cb681f70649d4791cc9586b5698e” –pretty=format:”%at %aN” -n 1[0.00843] &gt;&gt; git log “d7a38706a7489edf997c9142ab2bf2e62ebc7ca8” –pretty=format:”%at %aN” -n 1[0.00825] &gt;&gt; git log “c457ef0f91a880da238873790505e522d802484c” –pretty=format:”%at %aN” -n 1[0.01002] &gt;&gt; git log “d8608b5ce71aaa44a3afd8d34d730dadc7dd63ce” –pretty=format:”%at %aN” -n 1[0.00878] &gt;&gt; git log “869a4500faaffe27d3b075d293d7246ef4f98740” –pretty=format:”%at %aN” -n 1…\n生成的统计文件后，用浏览器打开目录中的index.html即可。SOLO项目的代码统计：\n此外，为了让一些前端同学（不熟悉python和linux环境）也能用这个工具，自己写了一个能够用web访问的小工具：\n见：https://github.com/heqiao2010/webGitstats\n","categories":["git"],"tags":["代码统计"]}]